<!DOCTYPE html>
<html lang='en'>
<head>
<meta charset='utf-8'>
<meta name='viewport' content='width=device-width, initial-scale=1, shrink-to-fit=no'>
<meta name='description' content='Sylvain Calinon'>
<meta name='author' content='Sylvain Calinon'>
<meta name='keywords' content='Sylvain Calinon, robotics, machine learning, robot learning, human-robot interaction, human-robot collaboration, learning from demonstration, programming by demonstration, artificial intelligence'>
<meta name='theme-color' content='#343a40'>
<link rel='icon' href='images/favicon.ico'>
<title>Sylvain Calinon</title>
<link href='css/bootstrap.min.css' rel='stylesheet'>
<link href='css/main-template.css' rel='stylesheet'>
<link href='font-awesome/css/font-awesome.min.css' rel='stylesheet'>
<link href='https://fonts.googleapis.com/css?family=Lobster|Raleway' rel='stylesheet'> 
<script type='text/x-mathjax-config'>
MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
});
</script>
<script type='text/javascript' async src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML' async></script>
</head>
<body>
<nav class='navbar navbar-expand-lg navbar-dark bg-dark fixed-top'>
<button class='navbar-toggler navbar-toggler-right' type='button' data-toggle='collapse' data-target='#navbarsExampleDefault' aria-controls='navbarsExampleDefault' aria-expanded='false' aria-label='Toggle navigation'>
<span class='navbar-toggler-icon'></span>
</button>
<a class='navbar-brand' href='index.htm'>
<h3 style='display: inline-block;'>Sylvain Calinon</h3>
<img src='images/pbd-thumbnail02.png' style='display: inline-block; margin-left: 10px;'>
</a>

<div class='collapse navbar-collapse' id='navbarsExampleDefault'>
<ul class='navbar-nav mr-auto'>
<li class='nav-item'><a class='nav-link' href='index.htm'>News</a></li>
<li class='nav-item'><a class='nav-link' href='cv.htm'>CV</a></li>
<li class='nav-item'><a class='nav-link' href='research.htm'>Research</a></li>
<li class='nav-item'><a class='nav-link' href='publications.htm'>Publications</a></li>
<li class='nav-item'><a class='nav-link' href='teaching.htm'>Teaching</a></li>
<li class='nav-item'><a class='nav-link' href='book.htm'>Book</a></li>
<li class='nav-item'><a class='nav-link' href='videos.htm'>Videos</a></li>
<li class='nav-item'><a class='nav-link' href='codes.htm'>Codes</a></li>
<li class='nav-item'><a class='nav-link' href='open-positions.htm'>Open positions </a></li>
<li class='nav-item active'><a class='nav-link' href='contact.htm'>Contact/Links <span class='sr-only'>(current)</span></a></li>	
</ul>
</div>
</nav>

<div class='container'>
<div class='main-template'>

<h1>FondueBot</h1>

<img class='figure-img img-fluid' src='images/fonduebot01.jpg'><br><br>

<p class='text-justify'>FondueBot can prepare Swiss fondues by pouring cheese and wine in a caquelon, and stirring the preparation by monitoring the heat of a liquid fuel stove. This skill has been reached by combining kinesthetic teaching (learning from demonstration) and motion optimization (optimal control).</p><br><br> 


<h4>Learning keypoints from physical guidance of the robot</h4><br>

<div class='row'>
<div class='col-md-8'>
<p class='text-justify'>Learning from demonstration is a field of research that aims at developing learning algorithms and intuitive interfaces to democratize the use of robots, by allowing people to teach robots new tasks without requiring an expertise in robotics or in computer programming.</p>
<p class='text-justify'>Kinesthetic teaching consists of physically guiding the robot to demonstrate the task to achieve. This learning technique is a form of human-robot collaboration, in which the robot compensates for the effect of gravity, so that the user can freely move the robot, without feeling its weight. It also gives the impression that there are no motors in the articulations of the robot.</p>
</div>
<div class='col-md-4'>
<img class='figure-img img-fluid' src='images/kinestheticteaching01.jpg'>
</div>
</div>
<br><br>

<h4>Self-refinement of the demonstrated task by optimization</h4><br>

<div class='row'>
<div class='col-md-8'>
<p class='text-justify'>With the position and force sensors located at the articulations, the robot can record the movement and behavior taught by the user to achieve the task. Kinesthetic teaching can be used to record a set of robot poses, but it remains hard for the user to demonstrate a continuous movement or a dynamic task that would fully exploit the robot capability. For this reason, the demonstration of the keypoints (key postures) is combined with optimization techniques, in order to let the robot exploit its 7 articulations in an optimal manner.</p>
<p class='text-justify'>Thus, the robot refines the demonstrated task by finding gestures to connect the different keypoints shown by the user. Instead of moving in straight line from one keypoint to the next, the robot generates a fluid and efficient motion that takes into account smoothness and timing aspects. This optimal control approach allows the robot to anticipate the full of keypoints requested by the user, while reducing the control effort required to achieve the task.</p>
</div>
<div class='col-md-4'>
<img class='figure-img img-fluid' src='images/ilqr_optimization01.jpg'>
</div>
</div>
<br><br>

<h4>Applications: robots that are close to us, that are parts of us, or that are far from us</h4><br>

<p class='text-justify'>Our research in the <a href='research.htm'>Robot Learning & Interaction group</a> at the <a href='https://www.idiap.ch/en' target='_blank'>Idiap Research Institute</a> focuses on human-centered robotics applications in which the robots can acquire new skills from only few demonstrations and interactions. It requires the development of models that can exploit the structure and geometry of the acquired data in an efficient way, the development of optimal control techniques that can exploit the learned task variations and coordination patterns, and the development of intuitive interfaces to acquire meaningful demonstrations.</p> 

<img class='figure-img img-fluid' src='images/structures01.jpg'><br><br><br>

<p class='text-justify'>The developed approaches can be applied to a wide range of manipulation skills, with robots that are either close to us (assistive and industrial robots), parts of us (prosthetics and exoskeletons), or far away from us (teleoperation).</p> 

<img class='figure-img img-fluid' src='images/targetedapplications01.jpg'><br>

</div><!-- /.main-template -->
</div><!-- /.container -->


<!-- Bootstrap core JavaScript placed at the end of the document so the pages load faster -->
<script src="https://code.jquery.com/jquery-3.1.1.slim.min.js" integrity="sha384-A7FZj7v+d/sdmMqp/nOQwliLvUsJfDHW+k9Omg/a/EheAdgtzNs3hpfag6Ed950n" crossorigin="anonymous"></script>
<script>window.jQuery || document.write('<script src="../../assets/js/vendor/jquery.min.js"><\/script>')</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/tether/1.4.0/js/tether.min.js" integrity="sha384-DztdAPBWPRXSA/3eYEEUWrWCy7G5KFbe8fFjk5JAIxUYHKkDx6Qin1DkWx51bBrb" crossorigin="anonymous"></script>
<script src="js/bootstrap.min.js"></script>
<!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
<!--<script src="assets/js/ie10-viewport-bug-workaround.js"></script>-->
</body>
</html>
