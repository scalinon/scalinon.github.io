<!DOCTYPE html>
<html lang='en'>
<head>
<meta charset='utf-8'>
<meta name='viewport' content='width=device-width, initial-scale=1, shrink-to-fit=no'>
<meta name='description' content='Sylvain Calinon'>
<meta name='author' content='Sylvain Calinon'>
<meta name='keywords' content='Sylvain Calinon, robotics, machine learning, robot learning, human-robot interaction, human-robot collaboration, learning from demonstration, programming by demonstration, artificial intelligence'>
<meta name='theme-color' content='#292b2c'>
<link rel='icon' href='images/favicon.ico'>
<title>Sylvain Calinon</title>
<link href='css/bootstrap.min.css' rel='stylesheet'>
<link href='css/main-template.css' rel='stylesheet'>
<link href='font-awesome/css/font-awesome.min.css' rel='stylesheet'>
<link href='https://fonts.googleapis.com/css?family=Lobster|Raleway' rel='stylesheet'> 
<script type='text/x-mathjax-config'>
MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
});
</script>
<script type='text/javascript' async src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML' async></script>
</head>
<body>
<nav class='navbar navbar-expand-lg navbar-dark bg-dark fixed-top'>
<button class='navbar-toggler navbar-toggler-right' type='button' data-toggle='collapse' data-target='#navbarsExampleDefault' aria-controls='navbarsExampleDefault' aria-expanded='false' aria-label='Toggle navigation'>
<span class='navbar-toggler-icon'></span>
</button>
<a class='navbar-brand' href='index.htm'>
<h3 style='display: inline-block;'>Sylvain Calinon</h3>
<img src='images/pbd-thumbnail02.png' style='display: inline-block; margin-left: 20px;'>
</a>

<div class='collapse navbar-collapse' id='navbarsExampleDefault'>
<ul class='navbar-nav mr-auto'>
<li class='nav-item'><a class='nav-link' href='index.htm'>News</a></li>
<li class='nav-item'><a class='nav-link' href='cv.htm'>CV</a></li>
<li class='nav-item'><a class='nav-link' href='research.htm'>Research</a></li>
<li class='nav-item'><a class='nav-link' href='publications.htm'>Publications</a></li>
<li class='nav-item'><a class='nav-link' href='teaching.htm'>Teaching</a></li>
<li class='nav-item'><a class='nav-link' href='book.htm'>Book</a></li>
<li class='nav-item'><a class='nav-link' href='videos.htm'>Videos</a></li>
<li class='nav-item active'><a class='nav-link' href='codes.htm'>Codes <span class='sr-only'>(current)</span></a></li>
<li class='nav-item'><a class='nav-link' href='open-positions.htm'>Open positions </a></li>
<li class='nav-item'><a class='nav-link' href='contact.htm'>Contact/Links</a></li>	
</ul>
</div>
</nav>

<div class='container'>
<div class='main-template'>

<h3>Older source codes</h3>

<p>This page presents a list of older source codes developed at the <a href='http://www.iit.it/en/advr-labs/learning-and-interaction.html' target='_BLANK' title='website'>Learning and Interaction Lab</a>, Department of Advanced Robotics, Italian Institute of Technology (IIT), and at the <a href='http://lasa.epfl.ch' target='_BLANK' title='website'>Learning Algorithms and Systems Laboratory (LASA)</a>, Ecole Polytechnique Federale de Lausanne (EPFL).</p>

<!--<p><img class='miniicon' src='minipng/matlab.png'>&nbsp; 
The Matlab/Octave programs on this page are free for academic use.<br>Most of the source codes are implementations of the algorithms described in the book <a href='book.php'>"Robot Programming by Demonstration: A Probabilistic Approach"</a>.</p>
<p><strong>Please provide references to the authors' publications in works using parts of these codes.</strong></p>
<p><img class='miniicon' src='minipng/tux.png'><img class='miniicon' src='minipng/visualstudio.png'>
<img class='miniicon' src='minipng/macos.png'>&nbsp; 
The GMM-GMR sourcecode is also available in C/C++ (platform independent) at 
<a href="http://sourceforge.net/projects/gmm-gmr" target="_BLANK">Sourceforge.net</a>.</p>
<br>-->


<br>
<a name='Task-parameterized tensor GMM with missing frames'></a>
<h4><b>Task-parameterized tensor GMM with missing frames</b></h4>
<a href="images/tensorGMM-missingFrames01.jpg" rel="lightbox">
<img class="widethumb" src='images/tensorGMM-missingFrames-thumbnail01.jpg'>
</a>

<p>Demonstration a task-parameterized probabilistic model encoding movements in the form of virtual spring-damper systems acting in multiple frames of reference. Each candidate coordinate system observes a set of demonstrations from its own perspective. When one task parameter is not observable, the corresponding part in the data will be missing (third order sparse tensor data) and this information is taken into account in the learning and reproduction parts. 
The task is a via point passing task, starting from one point, passing through a second point and ending in a third point. A frame of references (task parameters) is attached to each via point, complemented by a fixed frame of reference at the origin.</p>  

<h4>Download</h4>
<p><img class='miniicon' src='minipng/compress.png'>
<a href="download/task-parameterized-tensor-GMM-missing-frames.zip">Download task-parameterized tensor GMM with missing frames sourcecode</a></p>

<h4>Usage</h4>
<p>Unzip the file and run 'demo1' in Matlab.</p>

<h4>Reference</h4>
<ul><li>Alizadeh, T., Calinon, S. and Caldwell, D.G. (2014) <b>Learning from demonstrations with partially observable task parameters</b>. Proc. IEEE Intl Conf. on Robotics and Automation (ICRA).</li></ul>
<br>

	
<br>
<a name='Task-parameterized tensor GMM with LQR'></a>
<h4><b>Task-parameterized tensor GMM with LQR</b></h4>
<a href="images/tensor-GMM-LQR01.png" rel="lightbox">
<img class="widethumb" src='images/tensor-GMM-LQR-thumbnail01.png'>
</a>

<p>Demonstration a task-parameterized probabilistic model encoding movements in the form of virtual spring-damper systems acting in multiple frames of reference. Each candidate coordinate system observes a set of demonstrations from its own perspective, by extracting an attractor path whose variations depend on the relevance of the frame through the task. This information is exploited to generate a new attractor path corresponding to new situations (new positions and orientation of the frames), while the predicted covariances are exploited by a linear quadratic regulator (LQR) to estimate the stiffness and damping feedback terms of the spring-damper systems, resulting in a minimal intervention control strategy.</p>  

<h4>Download</h4>
<p><img class='miniicon' src='minipng/compress.png'>
<a href="download/task-parameterized-tensor-GMM-with-LQR.zip">Download task-parameterized tensor GMM with LQR sourcecode</a></p>

<h4>Usage</h4>
<p>Unzip the file and run 'demo01' in Matlab. Several reproduction algorithms can be selected by commenting/uncommenting lines 89-91 and 110-112 in demo01.m (finite/infinite horizon LQR or dynamical system with constant gains). 'demo_testLQR01' and 'demo_testLQR02' can also be run as examples of LQR.</p>

<h4>Reference</h4>
<ul><li>Calinon, S., Bruno, D. and Caldwell, D.G. (2014) <b>A task-parameterized probabilistic model with minimal intervention control</b>. Proc. of the IEEE Intl Conf. on Robotics and Automation (ICRA).</li></ul>
<br>

	
<br>
<a name='Task-parameterized GMM'></a>
<h4><b>Task-parameterized GMM</b></h4>
<p>Training of a task-parameterized Gaussian mixture model (GMM) based on candidate frames of reference.
The proposed task-parameterized GMM approach relies on the linear transformation and product properties of
Gaussian distributions to derive an expectation-maximization (EM) algorithm to train the model.
The proposed approach is contrasted with an implementation of the approach proposed by Wilson and Bobick in
1999, with an implementation applied to GMM (that we will call PGMM) and following the model described in
"Parametric Hidden Markov Models for Gesture Recognition", IEEE Trans. on Pattern Analysis and Machine
Intelligence.<br>
In contrast to the standard PGMM approach, the new approach that we propose allows the parameterization of
both the centers and covariance matrices of the Gaussians. It has been designed for targeting problems in
which the task parameters can be represented in the form of coordinate systems, which is for example the
case in robot manipulation problems.</p>  

<h4>Download</h4>
<p><img class='miniicon' src='minipng/compress.png'>
<a href="download/task-parameterized-GMM.zip">Download task-parameterized GMM <b>Matlab</b> sourcecode</a></p>
<p><img class='miniicon' src='minipng/compress.png'>
<a href="download/task-parameterized-GMM-cpp-cmdLine.zip">Download task-parameterized GMM <b>C++ (command line version)</b> sourcecode</a></p>
<p>(see also <a href='sourcecodes.php#DMP learned by GMR'>DMP LEARNED BY GMR</a> sourcecode)</p>

<h4>Usage</h4>
<p>For the Matlab version, unzip the file and run 'demo1' or 'demo2' in Matlab.<br>
For the C++ version, unzip the file and follow the instructions in the ReadMe.txt file.</p>

<h4>Reference</h4>
<ul><li>Calinon, S., Li, Z., Alizadeh, T., Tsagarakis, N.G. and Caldwell, D.G. (2012) <b>Statistical dynamical systems for skills acquisition in humanoids</b>. Proc. of the IEEE Intl Conf. on Humanoid Robots (Humanoids).</li></ul>
<br>

<h4>Demo 1 - Simple example of task-parameterized GMM learning and comparison with standard PGMM</h4>

<a href="images/task-parameterized-GMM.png" rel="lightbox">
<img class="widethumb" src='images/task-parameterized-GMM-thumbnail.png'>
</a>

<p>This example uses 3 trajectories demonstrated in a frame of reference that varies from one demonstration
to the other. A model of 3 Gaussian components is used to encode the data in the different frames, by providing the
parameters of the coordinate systems as inputs (transformation matrix A and offset vector b).</p>

<br>

<h4>Demo 2 - Example of task-parameterized movement learning with DS-GMR (statistical dynamical systems based on Gaussian mixture regression) </h4>

<a href="images/task-parameterized-GMM2.png" rel="lightbox">
<img class="widethumb" src='images/task-parameterized-GMM2-thumbnail.png'>
</a>

<p>This demo shows how the approach can be combined with the DS-GMR model to learn movements modulated
with respect to different frames of reference. The DS-GMR model is a statistical dynamical system approach
to learn and reproduce movements with a superposition of virtual spring-damper systems
retrieved by Gaussian mixture regression (GMR). For more details, see the 'DMP-learned-by-GMR-v1.0' example
code downloadable from the website below.</p>
	
<br>
<a name='DMP learned by GMR'></a>
<h4><b>DMP learned by GMR</b></h4>
<h4>Download</h4>
<p><img class='miniicon' src='minipng/compress.png'>
<a href="download/DMP-learned-by-GMR.zip">Download DMP learning with GMR <b>Matlab</b> sourcecode</a></p>
<p><img class='miniicon' src='minipng/compress.png'>
<a href="download/DMP-learned-by-GMR-cpp-cmdLine.zip">Download DMP learning with GMR <b>C++ (command line version)</b> sourcecode</a></p>
<p>(see also <a href='sourcecodes.php#Task-parameterized GMM'>TASK-PARAMETERIZED GMM</a> sourcecode)</p>

<h4>Usage</h4>
<p>For the Matlab version, unzip the file and run 'demo1' in Matlab.<br>
For the C++ version, unzip the file and follow the instructions in the ReadMe.txt file.</p>

<h4>Reference</h4>
<ul><li>Calinon, S., Li, Z., Alizadeh, T., Tsagarakis, N.G. and Caldwell, D.G. (2012) <b>Statistical dynamical systems for skills acquisition in humanoids</b>. Proc. of the IEEE Intl Conf. on Humanoid Robots (Humanoids).</li></ul>
<br>

<h4>Demo 1 - Simple example of DMP learning with GMR</h4>

<a href="images/DMP-learned-by-GMR.png" rel="lightbox">
<img class="widethumb" src='images/DMP-learned-by-GMR-thumbnail.jpg'>
</a>

<p>Simple example of estimating the parameters of a DMP (dynamic movement primitives) through GMR (Gaussian mixture regression).<br>
A DMP is composed of a virtual spring-damper system modulated by a non-linear force.
The standard method to train a DMP is to predefine a set of activations functions and estimate a set of force
components through a weighted least-squares (WLS) approach.
The weighted sum of force components form a non-linear force perturbing the system,
by moving it away from the point-to-point linear motion while following a desired trajectory.<br>
GMR is used here to learn the joint distribution between the decay term s (determined by a canonical dynamical
system) and the non-linear force variable to estimate.<br>
Replacing WLS with GMR has the following advantages:<br>
<ul>
<li>It provides a probabilistic formulation of DMP (e.g., to allow the exploitation of correlation and variation
information, and to make the DMP approach compatible with other statistical machine learning tools).</li>
<li>It simultaneously learns the non-linear force together with the activation functions. Namely, the Gaussian
kernels do not need to be equally spaced in time (or at predefined values of the decay term 's'), and the
bandwidths (variance of the Gaussians) are automatically estimated from the data instead of being hand-tuned.</li>
<li>It provides a more accurate approximation of the non-linear perturbing force with local linear models of
degree 1 instead of degree 0 (by exploiting the conditional probability properties of Gaussian distributions).</li>
</ul></p>
	
<br>
<a name='Continuous HSMM'></a>
<h4><b>Continuous HSMM</b></h4>
<h4>Download</h4>
<p><img class='miniicon' src='minipng/compress.png'> 
<a href="download/HSMM.zip">Download Continuous HSMM sourcecode</a></p>

<h4>Usage</h4>
<p>Unzip the file and run 'demo1' in Matlab.</p>

<h4>Reference</h4>
<ul><li>Calinon, S., Pistillo, A. and Caldwell, D.G. (2011) <b>Encoding the time and space constraints of a task in explicit-duration hidden Markov model</b>. Proc. of the IEEE/RSJ Intl Conf. on Intelligent Robots and Systems (IROS).</li></ul>
<br>

<h4>Demo 1 - Simple example of continuous HSMM</h4>

<a href="images/HSMM-graph01.jpg" rel="lightbox">
<img class="widethumb" src='images/HSMM-graph01-thumbnail.jpg'>
</a>

<p>Simple example of the use of Hidden Semi-Markov Model (HSMM), a form of explicit-duration Hidden Markov model, to learn and reproduce trajectories.<br> The movement is represented as a combination of linear systems with a velocity dx computed iteratively as dx = sum_i h_i (A_i x + b_i), where h_i is a weight defined by HSMM.<br>A_i and b_i form a matrix and vector associated with state i of the HSMM.</p>
	
<br>
<a name='Rescaled GMM'></a>
<h4><b>Rescaled GMM</b></h4>
<h4>Download</h4>
<p><img class='miniicon' src='minipng/compress.png'> 
<a href="download/rescaledGMM.zip">Download Rescaled GMM sourcecode</a></p>

<h4>Usage</h4>
<p>Unzip the file and run 'demo1' in Matlab.</p>

<h4>Reference</h4>
<ul><li>Pistillo, A., Calinon, S. and Caldwell, D.G. (2011) <b>Bilateral Physical Interaction with a Robot Manipulator through a Weighted Combination of Flow Fields</b>. Proc. of the IEEE/RSJ Intl Conf. on Intelligent Robots and Systems (IROS).</li></ul>
<br>

<h4>Demo 1 - Simple example of Rescaled GMM</h4>

<a href="images/AB-Matlab01.jpg" rel="lightbox">
<img class="widethumb" src='images/AB-Matlab01-thumbnail.jpg'>
</a>

<p>Simple example of using a Gaussian Mixture Models (GMMs) to learn and reproduce movements represented as a combination of linear
systems with a velocity command dx computed iteratively as dx = sum_i h_i (A_i x + b_i), where A_i and b_i form a matrix and vector associated with state i of the GMM. 
The novelty here is that h_i is a weight originally defined by GMM and rescaled during reproduction to authorize motion commands only in the regions of the task demonstrations, while the movemement fades away outside those (according to the task constraints, that is, local variability).<br>With the new weighting mechanism, each linear subsystem becomes independent from the others.</p>
	
<br>
<a name='Correlated DMP '></a>
<h4><b>Correlated DMP </b></h4>
<h4>Download</h4>
<p><img class='miniicon' src='minipng/compress.png'> 
<a href="download/corrDMP.zip">Download corrDMP sourcecode</a></p>

<h4>Usage</h4>
<p>Unzip the file and run 'demo1' in Matlab.</p>

<h4>Reference</h4>
<ul><li>Calinon, S., Sardellitti, I. and Caldwell, D.G. (2010) <b>Learning-based control strategy for safe human-robot interaction exploiting task and robot redundancies</b>. Proc. of the IEEE/RSJ Intl Conf. on Intelligent Robots and Systems (IROS).</li></ul>
<br>

<h4>Demo 1 - Mixture of correlated mass-spring-damper systems</h4>

<a href="images/corrDMP-graph01.png" rel="lightbox">
<img class="widethumb" src='images/corrDMP-graph01-thumbnail.jpg'>
</a>

<p>Learning and reproduction of a movement through a mixture of dynamical
systems (similar to Dynamic Movement Primitives), where variability and correlation information along the movement and among the different examples is encapsulated as a full stiffness matrix in a set of mass-spring-damper systems.<br> 
For each primitive (or state), learning of the virtual attractor points 
and associated stiffness matrices is done through least-squares regression.</p>
	
<br>
<a name='GMR Dynamics'></a>
<h4><b>GMR Dynamics</b></h4>
<h4>Download</h4>
<p><img class='miniicon' src='minipng/compress.png'>  
<a href="download/GMR-dynamics.zip">Download GMR Dynamics sourcecode</a></p>

<h4>Usage</h4>
<p>Unzip the file and run 'demo1' in Matlab.</p>

<h4>Reference</h4>
<ul>
<li>Calinon, S., D'halluin, F., Sauser, E.L., Caldwell, D.G. and Billard, A.G. (2009) <b>A probabilistic approach based on dynamical systems to learn and reproduce gestures by imitation</b>. IEEE Robotics and Automation Magazine.
</li></ul>
<br>

<h4>Demo 1 - Demonstration of a trajectory learning system robust to perturbation 
based on Gaussian Mixture Regression (GMR)</h4>

<a href="images/GMR-dynamics01.jpg" rel="lightbox">
<img class="widethumb" src='images/dynamicalSystem-thumbnail01.jpg'>
</a>

<p>This program first encodes a trajectory represented through time 't', position 'x' and velocity 'dx' 
in a joint distribution P(t,x,dx) through Gaussian Mixture 
Model (GMM) by using Expectation-Maximization (EM) algorithm. Gaussian Mixture Regression (GMR) 
is then used to estimate P(x,dx|t), which retrieves another GMM refining the joint distribution 
model of position and velocity.<br>
The learned skill can then be reproduced by combining an estimation of P(dx|x)
with an attractor to the demonstrated trajectories.</p>
	
<br>
<a name='Joint/task constraints'></a>
<h4><b>Joint/task constraints</b></h4>
<h4>Download</h4>
<p><img class='miniicon' src='minipng/compress.png'>  
<a href="download/joint-task-constraints.zip">Download Joint/task constraints sourcecode</a></p>

<h4>Usage</h4>
<p>Unzip the file and run 'demo1' in Matlab.</p>

<h4>Reference</h4>
<ul>
<li>Calinon, S. and Billard, A. (2008) 
<b>A Probabilistic Programming by Demonstration Framework Handling Constraints in Joint Space and Task Space</b>. 
IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pp. 367-372.</li></ul>
<br>

<h4>Demo 1 - Demonstration of the use of Gaussian Mixture Regression (GMR) and 
inverse kinematics to reproduce a task by considering constraints both 
in joint space and in task space</h4>

<a href="images/joint-task-constraints01.jpg" rel="lightbox">
<img class="widethumb" src='images/joint-task-constraints01-thumbnail.jpg'>
</a>

<p>This program shows the simulation of a robotic arm composed of 2 links and moving in 2D space. 
Several demonstrations of a skill are provided, by 
starting from different initial positions. The skill consists of moving 
each joint sequentially and then writing the alphabet letter 'N' at a 
specific position in the 2D space.<br>
Constraints in joint space and in task space are represented
through Gaussian Mixture Models (GMMs) and Gaussian Mixture Regression 
(GMR). By using an inverse kinematics process based on a pseudo-inverse 
Jacobian, the constraints in task space are then projected in joint 
space. By considering the projected constraints with the ones originally 
encoded in joint space, an optimal controller is found for the 
reproduction of the task. We see through this example that the system is
able to generalize the learned skill to new robotic arms (different links
lengths) and to new initial positions of the robot.</p>
	
<br>
<a name='Cone-plane intersection'></a>
<h4><b>Cone-plane intersection</b></h4>
<h4>Download</h4>
<p><img class='miniicon' src='minipng/compress.png'>  
<a href="download/cone-plane-intersection.zip">Download Cone-plane intersection sourcecode</a></p>

<h4>Usage</h4>
<p>Unzip the file and run 'demo1' in Matlab.</p>

<h4>References</h4>
<ul>
<li>Calinon, S. and Billard, A. (2006) 
<b>Teaching a Humanoid Robot to Recognize and Reproduce Social Cues</b>. 
IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN), pp. 346-351.
</li></ul>
<br>

<h4>Demo 1 - Demonstration of a cone-plane intersection interpreted in terms of Gaussian
Probability Density Function (PDF)</h4>

<a href="images/cone-plane-graph01.jpg" rel="lightbox">
<img class="widethumb" src='images/cone-plane-graph01-thumbnail.jpg'>
</a>

<p>This program computes the intersection between a cone and a plane, 
represented as a Gaussian Probability Density Function
(PDF). The algorithm can be used to extract probabilistically information 
concerning gazing or pointing direction. Indeed, by representing a visual 
field as a cone and representing a table as a plane, the Gaussian distribution 
can be used to compute the probability that one object on the table is 
observed/pointed by the user.</p>
	
<br>
<a name='GMM incremental learning'></a>
<h4><b>GMM incremental learning</b></h4>
<h4>Download</h4>
<p><img class='miniicon' src='minipng/compress.png'>  
<a href="download/GMM-incremental.zip">Download GMM incremental sourcecode</a></p>

<h4>Usage</h4>
<p>Unzip the file and run 'demo1' or 'demo2' in Matlab.</p>

<h4>References</h4>
<ul>
<li>Calinon, S. and Billard, A. (2007) 
<b>Incremental Learning of Gestures by Imitation in a Humanoid Robot</b>. 
Proceedings of the ACM/IEEE International Conference on Human-Robot Interaction (HRI), pp. 255-262.
</li></ul>
<br>

<h4>Demo 1 - Demonstration of an incremental learning process of Gaussian
Mixture Model (GMM) using a direct update method</h4>

<a href="images/plot-GMMincremental01.jpg" rel="lightbox">
<img class="widethumb" src='images/plot-GMMincremental01-thumbnail.jpg'>
</a>

<p>The demonstration loads a dataset consisting of several trajectories 
which are presented one-by-one to update the GMM parameters by using an
incremental version of the Expectation-Maximization (EM)
algorithm (direct update method). The learning mechanism only 
uses the latest observed trajectory to update the models (no historical
data is used).</p>

<h4>Demo 2 - Demonstration of an incremental learning process of Gaussian
Mixture Model (GMM) using a generative method</h4>

<p>The demonstration loads a dataset consisting of several trajectories 
which are presented one-by-one to update the GMM parameters by 
generating stochastically a new dataset from the current model, 
adding the new trajectory to this dataset and updating the GMM 
parameters using the resulting dataset, through a standard
Expectation-Maximization (EM) algorithm (generative method). 
The learning mechanism only uses the latest observed trajectory to 
update the models (no historical data is used).</p>
	
<br>
<a name='GMR multiple constraints '></a>
<h4><b>GMR multiple constraints </b></h4>
<h4>Download</h4>
<p><img class='miniicon' src='minipng/compress.png'>  
<a href="download/GMR-multiConstraints.zip">Download GMR multiConstraints sourcecode</a></p>

<h4>Usage</h4>
<p>Unzip the file and run 'demo1' in Matlab.</p>

<h4>References</h4>
<ul>
<li>Calinon, S. and Billard, A. (2007) 
<b>What is the Teacher's Role in Robot Programming by Demonstration? 
- Toward Benchmarks for Improved Learning</b>. 
Interaction Studies. Special Issue on Psychological Benchmarks in Human-Robot Interaction. 8:3, 441-464.
</li></ul>
<br>

<h4>Demo 1 - Demonstration of the reproduction of a generalized trajectory through 
Gaussian Mixture Regression (GMR), when considering two independent 
constraints represented separately in two Gaussian Mixture Models 
(GMMs)</h4>

<a href="images/plot-GMR-multiConstraints.jpg" rel="lightbox">
<img class="widethumb" src='images/plot-GMR-multiConstraints-thumbnail.jpg'>
</a>

<p>Through regression, a smooth generalized trajectory satisfying 
the constraints encapsulated in both GMMs is extracted, with associated
constraints represented as covariance matrices.<br>
The program loads two datasets, which are encoded separetely in two 
GMMs. GMR is then performed separately on the two datasets, and the 
resulting Gaussian distributions at each time step are multiplied to 
find an optimal controller satisfying both constraints, producing a 
smooth generalized trajectory across the two datasets.</p>
	
<br>
<a name='GMM latent space'></a>
<h4><b>GMM latent space</b></h4>
<h4>Download</h4>
<p><img class='miniicon' src='minipng/compress.png'>  
<a href="download/GMM-latentSpace.zip">Download GMM latent space sourcecode</a></p>

<h4>Usage</h4>
<p>Unzip the file and run 'demo1' in Matlab.</p>

<h4>References</h4>
<ul>
<li>Calinon, S. and Billard, A. (2005) <strong>Recognition and Reproduction of Gestures using a Probabilistic Framework combining PCA, ICA and HMM</strong>. In Proceedings of the International Conference on Machine Learning (ICML), pp. 105-112.</li>
</ul>
<br>

<h4>Demo 1 - Demonstration of a probabilistic encoding through Gaussian Mixture Model (GMM) in
a latent space of motion extracted by Principal Component Analysis (PCA)</h4> 

<a href="images/GMM-latentSpace-graph01.jpg" rel="lightbox">
<img class="widethumb" src='images/GMM-latentSpace-graph01-thumbnail.jpg'>
</a>

<p>This programs loads a dataset, finds a latent space of lower dimensionality
encapsulating the important characteristics of the motion using 
Principal Component Analysis (PCA), trains a Gaussian Mixture Model (GMM) 
using the data projected in this latent space, and projects back the Gaussian
distributions in the original data space. Training a GMM with 
EM algorithm usually fails to find a good local optimum when data are
high-dimensional. By projecting the original dataset in a latent space 
as a pre-processing step, GMM training can be performed in a robust way,
and the Gaussian parameters can be projected back to the original data
space.</p>
	
<br>
<a name='GMM-GMR '></a>
<h4><b>GMM-GMR </b></h4>
<h4>Download</h4>
<p><img class='miniicon' src='minipng/compress.png'>  
<a href="download/GMM-GMR.zip">Download GMM-GMR sourcecode</a></p>

<h4>Usage</h4>
<p>Unzip the file and run 'demo1', 'demo2' or 'demo3' in Matlab.</p>

<h4>References</h4>
<ul>
<li>Calinon, S., Guenter, F. and Billard, A. (2007) 
<b>On Learning, Representing and Generalizing a Task in a Humanoid Robot</b>. 
IEEE Transactions on Systems, Man and Cybernetics, Part B. 37:2, 286-298.</li>
</ul>
<br>

<h4>Demo 1 - Demonstration of the generalization process using Gaussian Mixture Regression
(GMR)</h4>

<a href="images/GMM-GMR-graph01.jpg" rel="lightbox">
<img class="widethumb" src='images/GMM-GMR-graph01-thumbnail.jpg'>
</a>

<p>The program loads a 3D dataset, trains a Gaussian Mixture Model 
(GMM), and retrieves a generalized version of the dataset with associated 
constraints through Gaussian Mixture Regression (GMR). Each datapoint 
has 3 dimensions, consisting of 1 temporal value and 2 spatial values 
(e.g., drawing on a 2D Cartesian plane). A sequence of temporal values is 
used as query points to retrieve a sequence of expected spatial 
distribution through Gaussian Mixture Regression (GMR).</p>

<h4>Demo 2 - Demonstration of Gaussian Mixture Regression (GMR) using spatial components as query points 
of arbitrary dimensions</h4> 

<a href="images/GMM-GMR-graph02.jpg" rel="lightbox">
<img class="widethumb" src='images/GMM-GMR-graph02-thumbnail.jpg'>
</a>

<p>The programs loads a 4D dataset, trains a 
Gaussian Mixture Model (GMM), and uses query points of 2 dimensions to 
retrieve a generalized version of the data for the remaining 2 dimensions, 
with associated constraints, through Gaussian Mixture Regression (GMR).
Each datapoint has 4 dimensions, consisting of 2x2 spatial values 
(e.g., drawing on a 2D Cartesian plane simultaneously with right and left 
hand). A new sequence of 2D spatial values (data for left hand) is 
loaded and used as query points to retrieve a sequence of expected 
spatial distribution for the remaining dimensions (data for right 
hand), through Gaussian Mixture Regression (GMR).</p>

<h4>Demo 3 - Demonstration of the smooth transitions properties of data retrieved by 
Gaussian Mixture Regression (GMR)</h4>

<a href="images/GMM-GMR-graph03.jpg" rel="lightbox">
<img class="widethumb" src='images/GMM-GMR-graph03-thumbnail.jpg'>
</a>

<p>This program loads two 3D datasets, 
trains two separates Gaussian Mixture Model (GMM), and retrieves a 
generalized version of the two datasets concatenated in time, with 
associated constraints, through Gaussian Mixture Regression (GMR). 
Each datapoint has 3 dimensions, consisting of 1 temporal value and 2 
spatial values (e.g., drawing on a 2D Cartesian plane). A sequence of 
temporal values is used as query points to retrieve a sequence of 
expected spatial distribution through Gaussian Mixture Regression (GMR).
The position of the last datapoint in the first dataset is not consistent
with the first datapoint of the second dataset. However, by encoding 
separately the two datasets in GMM and concatenating the components in 
a single model, a smooth signal with smooth 
transition between the two data is retrieved through regression.</p>
	</div><!-- /.main-template -->
</div><!-- /.container -->


<!-- Bootstrap core JavaScript placed at the end of the document so the pages load faster -->
<script src="https://code.jquery.com/jquery-3.1.1.slim.min.js" integrity="sha384-A7FZj7v+d/sdmMqp/nOQwliLvUsJfDHW+k9Omg/a/EheAdgtzNs3hpfag6Ed950n" crossorigin="anonymous"></script>
<script>window.jQuery || document.write('<script src="../../assets/js/vendor/jquery.min.js"><\/script>')</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/tether/1.4.0/js/tether.min.js" integrity="sha384-DztdAPBWPRXSA/3eYEEUWrWCy7G5KFbe8fFjk5JAIxUYHKkDx6Qin1DkWx51bBrb" crossorigin="anonymous"></script>
<script src="js/bootstrap.min.js"></script>
<!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
<!--<script src="assets/js/ie10-viewport-bug-workaround.js"></script>-->
</body>
</html>

