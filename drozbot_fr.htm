<!DOCTYPE html>
<html lang='en'>
<head>
<meta charset='utf-8'>
<meta name='viewport' content='width=device-width, initial-scale=1, shrink-to-fit=no'>
<meta name='description' content='Sylvain Calinon'>
<meta name='author' content='Sylvain Calinon'>
<meta name='keywords' content='Sylvain Calinon, robotics, machine learning, robot learning, frugal learning, human-robot collaboration, learning from demonstration, programming by demonstration, Idiap, model-based optimization, Riemannian geometry, tensor methods, tensor factorization, optimal control, ergodic control'>
<meta name='theme-color' content='#343a40'>
<link rel='icon' href='images/favicon.ico'>
<title>Sylvain Calinon</title>
<link href='css/bootstrap.min.css' rel='stylesheet'>
<link href='css/main-template.css' rel='stylesheet'>
<link href='font-awesome/css/font-awesome.min.css' rel='stylesheet'>
<link href='https://fonts.googleapis.com/css?family=Lobster|Raleway' rel='stylesheet'> 

<link rel='stylesheet' href='https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/katex.min.css' integrity='sha384-bYdxxUwYipFNohQlHt0bjN/LCpueqWz13HufFEV1SUatKs1cm4L6fFgCi1jT643X' crossorigin='anonymous'>
<script defer src='https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/katex.min.js' integrity='sha384-Qsn9KnoKISj6dI8g7p1HBlNpVx0I8p1SvlwOldgi3IorMle61nQy4zEahWYtljaz' crossorigin='anonymous'></script>
<script defer src='https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/contrib/auto-render.min.js' integrity='sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05' crossorigin='anonymous'></script>
<script>
let macros = {
	'\\tp': '\\text{\\tiny{#1}}',
	'\\trsp' : '\\top',
	'\\psin' : '\\dagger',
	'\\eqref': '\\href{###1}{(\\text{#1})}',
	'\\ref': '\\href{###1}{\\text{#1}}',
	'\\label': '\\htmlId{#1}{}'
};
document.addEventListener('DOMContentLoaded', function() {
	renderMathInElement(document.body, {
		// customised options
		trust: (context) => ['\\htmlId', '\\href'].includes(context.command),
		macros: macros,
		// • auto-render specific keys, e.g.:
		delimiters: [
			{left: '$$', right: '$$', display: true},
			{left: '$', right: '$', display: false},
			{left: '\\(', right: '\\)', display: false},
			{left: '\\begin{equation}', right: '\\end{equation}', display: true},
			{left: '\\begin{equation*}', right: '\\end{equation*}', display: true},
			{left: '\\begin{align}', right: '\\end{align}', display: true},
			{left: '\\begin{align*}', right: '\\end{align*}', display: true},
			{left: '\\begin{alignat}', right: '\\end{alignat}', display: true},
			{left: '\\begin{gather}', right: '\\end{gather}', display: true},
			{left: '\\begin{CD}', right: '\\end{CD}', display: true},
			{left: '\\[', right: '\\]', display: true}
		],
		// • rendering keys, e.g.:
		throwOnError : false
	});
});
</script>

</head>

<body>
<nav class='navbar navbar-expand-lg navbar-dark bg-dark fixed-top'>
<button class='navbar-toggler navbar-toggler-right' type='button' data-toggle='collapse' data-target='#navbarsExampleDefault' aria-controls='navbarsExampleDefault' aria-expanded='false' aria-label='Toggle navigation'>
<span class='navbar-toggler-icon'></span>
</button>
<a class='navbar-brand' href='index.htm'>
<h3 style='display: inline-block;'>Sylvain Calinon</h3>
<img src='images/pbd-thumbnail02.png' style='display: inline-block; margin-left: 10px;'>
</a>

<div class='collapse navbar-collapse' id='navbarsExampleDefault'>
<ul class='navbar-nav mr-auto'>
<li class='nav-item'><a class='nav-link' href='index.htm'>News</a></li>
<li class='nav-item'><a class='nav-link' href='cv.htm'>CV</a></li>
<li class='nav-item'><a class='nav-link' href='research.htm'>Research</a></li>
<li class='nav-item'><a class='nav-link' href='publications.htm'>Publications</a></li>
<li class='nav-item'><a class='nav-link' href='teaching.htm'>Teaching</a></li>
<li class='nav-item'><a class='nav-link' href='book.htm'>Book</a></li>
<li class='nav-item'><a class='nav-link' href='videos.htm'>Videos</a></li>
<li class='nav-item'><a class='nav-link' href='codes.htm'>Codes</a></li>
<li class='nav-item'><a class='nav-link' href='open-positions.htm'>Open positions </a></li>
<li class='nav-item active'><a class='nav-link' href='contact.htm'>Contact/Links <span class='sr-only'>(current)</span></a></li>	
</ul>
</div>
</nav>

<div class='container'>
<div class='main-template'>



<p class='float-right'><a href='drozbot.htm'>English</a> / <b>Français</b></p>

<h1>drozBot, le robot portraitiste</h1>

<div class='row'>
<div class='col-md-3'>
<img class='figure-img img-fluid' src='images/drozbot-setup01.jpg'>
</div>
<div class='col-md-9'>
<p class='text-justify'>drozBot est un robot qui dessine avec des gestes rapides et fluides proches de ceux d'un·e artiste. A partir d'une photo, il tire le portrait de la personne en traçant une série de traits à l'encre de Chine sur une feuille de papier.</p> 
<p class='text-justify'>Guidé par l’intelligence artificielle et un modèle de mouvements inspirés de l'écriture humaine, il peut transformer une image en dessin abstrait. Le résultat est surprenant : des traits expressifs, dynamiques et naturels, qui donnent l’impression que le robot sait dessiner plutôt que d'exécuter une série de commandes.</p>
</div>
</div>


<div class='row'>
<div class='col-md-12'>

<p class='text-justify'>drozBot utilise des technologies développées par le groupe <i>Robot Learning & Interaction</i> de l'Idiap. Le but est de générer des portraits rapidement avec trois objectifs principaux :
<ul> 
<li>pouvoir reconnaître la personne qui a été dessinée</li> 
<li>pouvoir reconnaître le style distinctif défini par l'artiste</li>
<li>pouvoir reconnaître la qualité des traits sur la base du portrait finalisé</li>
</ul> 
</p>

<p class='text-justify'>Le dernier objectif est obtenu en combinant des approches de plusieurs disciplines scientifiques, mêlant robotique, contrôle optimal et sciences du mouvement. Comme pour de la calligraphie, même si une personne ne regarde que le portrait final (aperçu figé), une esquisse réussie doit refléter la fluidité et l'habileté du mouvement qui a permis la réalisation du portrait.</p> 

<p class='text-justify'>Cet aspect de génération de mouvement est au coeur du travail de recherche du groupe <i>Robot Learning & Interaction</i> de l'Idiap. Le groupe se concentre sur la collaboration homme-robot et sur la représentation de mouvements pour faciliter le transfert de tâches de manipulation, pour diverses applications allant de l'industrie à l'assistance de personnes.</p> 


<h3>Collaboration Internationale : Entre Art, Science & Technologie</h3>

<p class='text-justify'>En collaboration avec divers chercheurs internationaux venant de l'<i>Université de Londres, Goldsmiths College</i> (<a href="https://www.gold.ac.uk/computing/people/berio-daniel-/" target="_blank">Daniel Berio</a> et <a href="https://www.gold.ac.uk/computing/people/f-folleymarie/" target="_blank">Frederic Fol Leymarie</a>) ou de l'<i>Université de Constance</i> (<a href="https://www.cgmi.uni-konstanz.de/" target="_blank">Michael Stroh et Oliver Deussen</a>), dans le cadre de projets tels que <a href="https://www.doc.gold.ac.uk/eacva/wp/index.php/collaborations/" target="_blank">EACVA (Embodied Agents in Contemporary Visual Art)</a>, le groupe <i>Robot Learning & Interaction</i> de l'Idiap explore comment étendre la collaboration homme-robot à des domaines touchant à l'art et à la créativité. Le robot est ici vu comme un nouvel outil pour les artistes, en étudiant de nouvelles méthodes de création.</p>

<p class='text-justify'>De la même manière qu'un·e artiste décide des pinceaux, stylos ou crayons utilisés, ainsi que de guides supplémentaires comme l'utilisation d'une règle pour tracer des traits plus droits ou d'un compas pour tracer des arcs de cercle plus réguliers, le robot peut être utilisé comme un nouveau type de guide et d'assistance.</p> 

<p class='text-justify'>Pour réaliser ceci, nos travaux de recherche explorent quelles interfaces peuvent permettre d'enseigner facilement à un robot l'assistance souhaitée par l'artiste. Par exemple, sous forme d'un style qu'on montre au robot (apprentissage par la démonstration), que ce dernier doit ensuite répéter pour de nouveaux contenus ou sur de nouvelles parties du canvas.<p> 

<p class='text-justify'>Dans cette vision de recherche, notre groupe s'intéresse au développement de technologies intuitives pour qu'un robot puisse apprendre par imitation, combiné avec des interfaces pour pouvoir re-programmer facilement ces machines, sans faire appel à des connaissances en robotique ou en langage informatique (approche "no-code").</p>


<h3>Collaboration Interdisciplinaire à l'Idiap</h3>

<p class='text-justify'>drozBot vise des thèmes de recherche variés de l'Idiap autour de l'intelligence artificielle, s'inspirant par exemple des résultats de recherche sur l'interaction sociale homme-robot (<a href="https://emmanuel-senft.github.io/" target="_blank">Emmanuel Senft</a>), sur la biométrie (<a href="https://www.idiap.ch/en/scientific-research/biometrics-security-and-privacy/index_html" target="_blank">Sébastien Marcel</a>), sur la perception (<a href="https://www.idiap.ch/~odobez/" target="_blank">Jean-Marc Odobez</a>) ou sur les représentations sémantiques et symboliques pour des modèles de réseaux de neurones (<a href="https://www.idiap.ch/~afreitas/" target="_blank">André Freitas</a>, <a href="https://www.idiap.ch/en/about/people/1124" target="_blank">Paola Merlo</a>).</p>  


<h3>Mouvements et Gestes Fluides</h3>

<p class='text-justify'>Dans le domaine artistique, les approches de deep learning, avec des modèles génératifs, ont démocratisé (pour le meilleur ou pour le pire) la génération d'images à partir de descriptions textuelles. Ces modèles d'IA génèrent des images sous forme de pixels. Un robot génère au contraire des tracés et des trajectoires, avec un contrôle au niveau de ses articulations. De plus, au contraire de l'art numérique, le robot doit faire face au monde réel, avec des contraintes géométriques et physiques, devant par exemple compenser les effets de la gravité lorsqu'il déplace son bras tenant un pinceau imbibé d'encre.</p> 

<p class='text-justify'>Le défi scientifique est de définir des représentations mathématiques pour imiter les capacités du mouvement humain, avec des gestes fluides et rapides pour un rendu esthétique des tracés à l'encre de Chine. Pour ceci, le mouvement à générer est un aspect crucial, en contrôlant à la fois l'orientation et la trajectoire du pinceau, ainsi que la pression appliquée sur le papier.</p> 


<h3>IA et Robotique</h3>

<p class='text-justify'>Pour aider le robot à planifer les séries de traits qu'il doit générer, d'autres outils d'IA sont utilisés pour détecter automatiquement, à partir de l'image provenant d'une caméra, quelle est la pose de la personne sur l'image, et où se situent les éléments les plus importants du visage tels que les yeux, la bouche et le nez. Les autres éléments de l'image tels que l'arrière-plan, les cheveux ou les lunettes sont détectés d'une manière similaire. Ces informations sont utiles au robot pour déterminer quelle concentration et précision de traits sont requises dans le portrait, en se concentrant sur les éléments les plus importants et en gardant une esquisse plus rapide pour des informations moins importantes.<p>

<p class='text-justify'>Les tracés planifiés par le robot doivent ensuite être transformés en mouvements fluides pour mimiquer les gestes de l'artiste, en manipulant le pinceau de manière habile et en utilisant un encrier de manière adroite pour maintenir la quantité idéale d'encre.</p>


<h3>Publications Scientifiques :</h3>

<p><a href='https://calinon.ch/paper3111.htm' target='_blank'>Berio, D., Clivaz, G., Stroh, M., Deussen, O., Plamondon, R., Calinon, S. and Leymarie, F.F. (2025). <strong>Image-driven robot drawing with rapid lognormal movements</strong>. In Proc. IEEE Intl Symp. on Robot and Human Interactive Communication (Ro-Man).</a></p>

<p><a href='https://calinon.ch/paper4074.htm' class='nodecor'>Berio, D., Stroh, M., Calinon, S., Fol Leymarie, F., Deussen, O. and Shamir, A. (2025). <strong>Neural Image Abstraction Using Long Smoothing B-splines</strong>. ACM Transactions on Graphics (ToG).</a></p>

<p><a href='https://calinon.ch/paper3111.htm' target='_blank'>Berio, D., Clivaz, G., Stroh, M., Deussen, O., Plamondon, R., Calinon, S. and Leymarie, F.F. (2025). <strong>Image-driven robot drawing with rapid lognormal movements</strong>. In Proc. IEEE Intl Symp. on Robot and Human Interactive Communication (Ro-Man).</a></p> 

<p><a href='https://calinon.ch/paper3110.htm' target='_blank'>Berio, D., Calinon, S., Plamondon, R. and Leymarie, F. F. (2025). <strong>Differentiable rasterization of minimum-time sigma-lognormal trajectories</strong>. In Proc. 22nd Conference of the International Graphonomics Society (IGS).</a></p>

<p><a href='https://calinon.ch/paper3109.htm' target='_blank'>Calinon, S. (2025). <strong>Movement Generation and Drawing in Robotics</strong>. In Proc. 22nd Conference of the International Graphonomics Society (IGS).</a></p> 

<p><a href='https://calinon.ch/paper4055.htm' target='_blank'>Löw, T., Maceiras, J. and Calinon, S. (2022). <strong>drozBot: Using Ergodic Control to Draw Portraits</strong>. IEEE Robotics and Automation Letters (RA-L), 7:4, 11728-34.</a></p>


<h3>Contact :</h3> 

<p class='text-justify'><a href="https://calinon.ch/" target="_blank">Sylvain Calinon</a>, Senior Research Scientist à l'Idiap, responsable du groupe <i>Robot Learning & Interaction</i>. Email : <a href="mailto:sylvain.calinon@idiap.ch" target="_blank">sylvain.calinon@idiap.ch</a></p>

<p class='text-justify'>drozBot est le fruit d'une collaboration entre <a href="https://www.idiap.ch/~gclivaz/" target="_blank">Guillaume Clivaz</a>, <a href="https://www.idiap.ch/~jmaceiras/" target="_blank">Jérémy Maceiras</a>, <a href="https://tobiloew.ch/" target="_blank">Tobias Löw</a>, <a href="https://www.enist.org/" target="_blank">Daniel Berio</a>, et <a href="https://calinon.ch/" target="_blank">Sylvain Calinon</a>.</p>

<p class='text-justify'>Ce projet est soutenu par le <a href="https://www.snf.ch/fr" target="_blank">Fonds national suisse (FNS)</a> dans le cadre d'un projet Agora avec <a href="https://www.phaenomena.ch/fr" target="_blank">Phänomena</a>.</p>  

</div>
</div>

<!--
<div class='row'>
<div class='col-md-6'><img class='figure-img img-fluid' src='images/drozbot_museum01.jpg'></div>
<div class='col-md-6'><img class='figure-img img-fluid' src='images/drozbot_museum02.jpg'></div>
</div>

<center>
<iframe width="560" height="315" src="https://www.youtube.com/embed/F3UGtOrSIgQ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</center>

<p class='text-justify'>drozBot tire le portrait d'une personne en utilisant un stylo et une feuille de papier conventionnels. Il prend d'abord en photo la personne en cadrant son visage par reconnaissance de ses traits principaux (yeux, nez, bouche). Le portrait en format numérique est alors converti en un <b>mouvement fluide mimiquant les gestes d'un artiste</b>.</p>

<p class='text-justify'>Cette installation aspire à <b>explorer les frontières entre l'optimalité et l'aléatoire</b> dans les applications d'intelligence artificielle (IA). En effet, les mécanismes d'apprentissage derrière l'IA font souvent appel à des processus aléatoires pour la recherche de solutions (échantillonnage stochastique lors de l'optimisation). Cette composante aléatoire derrière ces algorithmes d'apprentissage permet par exemple à un robot de trouver des solutions rapidement sans avoir à tester chaque option possible.</p> 

<p class='text-justify'>drozBot part d'un autre principe, en résolvant à la place un <b>problème de contrôle optimal</b> visant à déterminer les tracés à effectuer pour couvrir au mieux la feuille de papier selon chaque portrait à dessiner. Ce procédé de génération de traits ne fait pas appel à une génération aléatoire. Pourtant, le résultat apparaît comme telle, avec <b>des tracés sous forme de gribouillis qui ne révèlent l'objectif global que lorsque le dessin est terminé</b>. Ces gribouillis paraissent aléatoires en les regardant de près, mais sont en réalité optimaux, avec un résultat unique quant à l'objectif global donné au robot.</p>

<p class='text-justify'>Pour atteindre cette capacité à dessiner, les objectifs du robot sont multiples. Il doit d'abord générer des gestes fluides, tout en contrôlant l'orientation et la pression du stylo sur le papier. Il doit ensuite définir une série de traits qui reproduisent les différents contrastes de l'image, en prévoyant des passages de traits plus nombreux dans les régions plus sombres de l'image, tout en réduisant le chemin total parcouru.</p>

<p class='text-justify'>En observant le robot à l'oeuvre, les gribouillis semblent, au départ, dénués de sens. L'objectif global ne se révèle que lors de la progression du dessin, et <b>la vue d'ensemble du portrait final fait disparaître l'apparence chaotique des premiers traits</b>.</p> 

<img class='figure-img img-fluid' src='images/drozBot-portraits02-web.jpg'><br><br>
<img class='figure-img img-fluid' src='images/drozbot_setup_fr01.jpg'><br><br>




<div class='p-3 bg-light text-dark border border-secondary text-justify'>
En robotique, cette technique s'appelle <b>contrôle ergodique</b>. Elle se démarque des approches standards de contrôle qui définissent la tâche à effectuer sous forme d'un point (ou une série de points) à atteindre précisément. Dans une approche de contrôle ergodique, à la place d'un point, <b>une région à explorer est donnée comme consigne au robot</b>. Le but du robot est alors de se déplacer pour <b>parcourir cette région de manière optimale</b>. Nous utilisons ces mêmes algorithmes dans nos travaux de recherche pour des tâches d'insertion dans des applications industrielles, ce qui permet au robot de compenser automatiquement les imprécisions de ses capteurs par un mouvement de recherche autour des points d'insertion.
</div>
<br>

<div class='p-3 bg-light text-dark border border-secondary text-justify'>
drozBot a fait partie de l'exposition <a href='https://www.museedelamain.ch/fr/1591/Intelligence-Artificielle' target='_blank'>Intelligence Artificielle: Nos Reflets Dans La Machine</a>, au Musée de la Main UNIL-CHUV à Lausanne, d'avril 2022 à septembre 2023.
</div>
-->

<!--
<img class='figure-img img-fluid' src='images/drozBot-part1.jpg'><br><br>
avec un bras articulé produisant une série de gribouillis révélant progressivement l'identité de la personne
<img class='figure-img img-fluid' src='images/drozBot-part2.jpg'><br><br>
<img class='figure-img img-fluid' src='images/drozBot-part3.jpg'><br><br>-->

</div><!-- /.main-template -->
</div><!-- /.container -->


<!-- Bootstrap core JavaScript placed at the end of the document so the pages load faster -->
<script src="https://code.jquery.com/jquery-3.1.1.slim.min.js" integrity="sha384-A7FZj7v+d/sdmMqp/nOQwliLvUsJfDHW+k9Omg/a/EheAdgtzNs3hpfag6Ed950n" crossorigin="anonymous"></script>
<script>window.jQuery || document.write('<script src="../../assets/js/vendor/jquery.min.js"><\/script>')</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/tether/1.4.0/js/tether.min.js" integrity="sha384-DztdAPBWPRXSA/3eYEEUWrWCy7G5KFbe8fFjk5JAIxUYHKkDx6Qin1DkWx51bBrb" crossorigin="anonymous"></script>
<script src="js/bootstrap.min.js"></script>
<!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
<!--<script src="assets/js/ie10-viewport-bug-workaround.js"></script>-->
</body>
</html>
