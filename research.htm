<!DOCTYPE html>
<html lang='en'>
<head>
<meta charset='utf-8'>
<meta name='viewport' content='width=device-width, initial-scale=1, shrink-to-fit=no'>
<meta name='description' content='Sylvain Calinon'>
<meta name='author' content='Sylvain Calinon'>
<meta name='keywords' content='Sylvain Calinon, robotics, machine learning, robot learning, human-robot interaction, human-robot collaboration, learning from demonstration, programming by demonstration, artificial intelligence, Idiap, model-based optimization, Riemannian geometry, tensor methods, tensor factorization, optimal control, ergodic control'>
<meta name='theme-color' content='#343a40'>
<link rel='icon' href='images/favicon.ico'>
<title>Sylvain Calinon</title>
<link href='css/bootstrap.min.css' rel='stylesheet'>
<link href='css/main-template.css' rel='stylesheet'>
<link href='font-awesome/css/font-awesome.min.css' rel='stylesheet'>
<link href='https://fonts.googleapis.com/css?family=Lobster|Raleway' rel='stylesheet'> 

<link rel='stylesheet' href='https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/katex.min.css' integrity='sha384-bYdxxUwYipFNohQlHt0bjN/LCpueqWz13HufFEV1SUatKs1cm4L6fFgCi1jT643X' crossorigin='anonymous'>
<script defer src='https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/katex.min.js' integrity='sha384-Qsn9KnoKISj6dI8g7p1HBlNpVx0I8p1SvlwOldgi3IorMle61nQy4zEahWYtljaz' crossorigin='anonymous'></script>
<script defer src='https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/contrib/auto-render.min.js' integrity='sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05' crossorigin='anonymous'></script>
<script>
let macros = {
	'\\tp': '\\text{\\tiny{#1}}',
	'\\trsp' : '\\top',
	'\\psin' : '\\dagger',
	'\\eqref': '\\href{###1}{(\\text{#1})}',
	'\\ref': '\\href{###1}{\\text{#1}}',
	'\\label': '\\htmlId{#1}{}'
};
document.addEventListener('DOMContentLoaded', function() {
	renderMathInElement(document.body, {
		// customised options
		trust: (context) => ['\\htmlId', '\\href'].includes(context.command),
		macros: macros,
		// • auto-render specific keys, e.g.:
		delimiters: [
			{left: '$$', right: '$$', display: true},
			{left: '$', right: '$', display: false},
			{left: '\\(', right: '\\)', display: false},
			{left: '\\begin{equation}', right: '\\end{equation}', display: true},
			{left: '\\begin{equation*}', right: '\\end{equation*}', display: true},
			{left: '\\begin{align}', right: '\\end{align}', display: true},
			{left: '\\begin{align*}', right: '\\end{align*}', display: true},
			{left: '\\begin{alignat}', right: '\\end{alignat}', display: true},
			{left: '\\begin{gather}', right: '\\end{gather}', display: true},
			{left: '\\begin{CD}', right: '\\end{CD}', display: true},
			{left: '\\[', right: '\\]', display: true}
		],
		// • rendering keys, e.g.:
		throwOnError : false
	});
});
</script>

</head>

<body>
<nav class='navbar navbar-expand-lg navbar-dark bg-dark fixed-top'>
<button class='navbar-toggler navbar-toggler-right' type='button' data-toggle='collapse' data-target='#navbarsExampleDefault' aria-controls='navbarsExampleDefault' aria-expanded='false' aria-label='Toggle navigation'>
<span class='navbar-toggler-icon'></span>
</button>
<a class='navbar-brand' href='index.htm'>
<h3 style='display: inline-block;'>Sylvain Calinon</h3>
<img src='images/pbd-thumbnail02.png' style='display: inline-block; margin-left: 10px;'>
</a>

<div class='collapse navbar-collapse' id='navbarsExampleDefault'>
<ul class='navbar-nav mr-auto'>
<li class='nav-item'><a class='nav-link' href='index.htm'>News</a></li>
<li class='nav-item'><a class='nav-link' href='cv.htm'>CV</a></li>
<li class='nav-item active'><a class='nav-link' href='research.htm'>Research <span class='sr-only'>(current)</span></a></li>
<li class='nav-item'><a class='nav-link' href='publications.htm'>Publications</a></li>
<li class='nav-item'><a class='nav-link' href='teaching.htm'>Teaching</a></li>
<li class='nav-item'><a class='nav-link' href='book.htm'>Book</a></li>
<li class='nav-item'><a class='nav-link' href='videos.htm'>Videos</a></li>
<li class='nav-item'><a class='nav-link' href='codes.htm'>Codes</a></li>
<li class='nav-item'><a class='nav-link' href='open-positions.htm'>Open positions </a></li>
<li class='nav-item'><a class='nav-link' href='contact.htm'>Contact/Links</a></li>	
</ul>
</div>
</nav>

<div class='container'>
<div class='main-template'>



<h3>Frugal Learning of Robot Manipulation Skills</h3>

<p class='text-justify'>Research in the <i>Robot Learning & Interaction group</i> at the <i>Idiap Research Institute</i> targets <b>robot manipulation skills acquisition</b>, by considering both prehensile and non-prehensile forms of manipulation (e.g. sliding, pushing and pulling objects, whole-body manipulation with multiple contacts). When people play board games like chess or go, the activity is often thought as requiring smart sequences of moves using both anticipative and reactive capability to win the game. We rarely think of the additional underlying skill required to physically move the chess pieces or go stones on the board, because we don't need deep reasoning to master this <b>subconscious form of intelligence</b>. This brings a big bias in AI research: robots can beat humans at such games but are incapable of skillfully moving the game pieces by themselves. Indeed, current research effort in AI is largely steered toward our human-centric view about what seems difficult, often ignoring all other subconscious skills that our robots cannot yet fluently achieve. What makes the research challenge both hard and fascinating is that the such skills are tightly connected to our physical world and to embodied forms of intelligence.</p>
<p class='text-justify'>Similarly to humans, <b>robots can acquire manipulation skills by leveraging multiple learning strategies</b>, including guidance from others and self-practice. Human-guided learning can take various forms such as learning from demonstration, feedback or scaffolding (putting the robot in an environment so that it can efficiently progress). Similarly, self-practice involves various strategies and models, including reinforcement learning, intrinsic motivation and ergodic exploration.</p>
<p class='text-justify'>Having robots acting in a physical world requires us to consider cautiously the current trends in other research fields. To let robots learn, our research group adopts a <b>frugal learning perspective</b>, meaning that we view each example provided by a person to the robot or each trial executed by the robot as an expensive process that cannot be blindly considered. We believe that considering data in such a way will eventually enable long-term progress in the field of robotics, by better understanding and exploiting the role of learning in robot manipulation skill acquisition, and by wisely balancing the roles of data-driven and model-based approaches in robotics. Thus, instead of viewing learning as a cheap alternative to problem modeling, our work tries to focus on the aspects that we believe really need to be learned, by injecting and combining known representations and models (which do not need to be exact), so that learning can be simplified. This view naturally yields a multidisciplinary research line at the crossroad of <b>robot learning, model-based optimization, optimal control, geometric representations and human-robot collaboration</b>, with inspiration from the ways humans and animals acquire skills.</p>
<p class='text-justify'>The manipulation skills acquisition methods that we developed can be applied to a wide range of manipulation skills, with robots that are either close to us (<b>assistive and industrial robots</b>), parts of us (<b>prosthetics and exoskeletons</b>), or far away from us (<b>teleoperation</b>). Our research is supported by the <a href='https://ec.europa.eu/programmes/horizon2020/' target='_blank'>European Commission</a>, by the <a href='http://www.snf.ch/en/' target='_blank'>Swiss National Science Foundation</a>, by the <a href='https://www.sbfi.admin.ch/sbfi/en/home/seri/seri.html' target='_blank'>State Secretariat for Education, Research and Innovation</a>, and by the <a href='https://www.innosuisse.ch/inno/en/home.html' target='_blank'>Swiss Innovation Agency</a>.</p> 
<p class='text-justify'>You can also download our <a href='papers/SylvainCalinon-researchStatement.pdf' target='_blank'>research statement as a PDF file</a>.</p> 
<br>

<center>
<iframe width="560" height="315" src="https://www.youtube.com/embed/5A7cZw5_KMI" title="YouTube video player" style="border:1px solid black;" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</center>


<br><br><br><br><br><br>
<a class='anchor' id='smalldata'></a>
<h4 class='p-2 text-white bg-dark'>LEARNING IN A HANDFUL OF TRIALS</h4>
<br>
<div class='row'>
<div class='col-md-12'>
<img src='images/datafeed-small03.png' class='wrappedimg'>
<p class='text-justify'>The field of machine learning has evolved toward approaches relying on huge amounts of data. In several application domains, these big datasets are already available, or are inexpensive to collect/produce. In contrast, robotics is characterized by a different problem setting. It should instead be viewed as a <b>wide-ranging data problem</b>, with models that could start learning from small datasets, and that could still exploit more data if such data become available during the robot's lifespan.</p> 
<p class='text-justify'>The current trend of machine learning relying on big datasets can bias the development of robot learning approaches in a negative way. In contrast to other fields, the data formats in robotics vary significantly across tasks, environments, users and platforms (different sensors and actuators, not only in formats but also in modalities and organizations). Then, the learned models often need to be interpretable to provide guarantees and to be linked to other techniques. For these reasons, my work focuses on <b>robot learning approaches that can rely on only few demonstrations or trials</b>.</p>
<p class='text-justify'>The main challenge boils down to <b>finding structures that can be used in a wide range of tasks</b>, which are discussed next and include (from high level to low level):</p>
<!--<ul>
<li><a href='#learning'>Learning structures</a></li>
<li><a href='#combination'>Combination structures</a></li>
<li><a href='#geometric'>Geometric structures</a></li>
<li><a href='#data'>Data structures</a></li>
</ul>-->
</div>
</div>
<div class='row'>
<div class='col-md-3 text-center'><a href='#geometric'><img class='figure-img img-fluid' src='images/structure-geometric-small01.jpg'><br>Geometric structures</a></div>
<div class='col-md-3 text-center'><a href='#data'><img class='figure-img img-fluid' src='images/structure-data-small01.jpg'><br>Data structures</a></div>
<div class='col-md-3 text-center'><a href='#combination'><img class='figure-img img-fluid' src='images/structure-combination-small01.jpg'><br>Combination structures</a></div>
<div class='col-md-3 text-center'><a href='#learning'><img class='figure-img img-fluid' src='images/structure-learning-small01.jpg'><br>Learning structures</a></div>
</div>
<div class='row'>
<div class='col-md-12'>
<p class='text-justify'>Efficient robot skills acquisition requires the right trade-off between learning and exploitation of these different form of structures (at model and algorithm levels).</p>
<div class='p-3 bg-light text-dark border'>
<p><b>Reference:</b></p>
<p><a href='paper7002.htm' class='nodecor'>Chatzilygeroudis, K., Vassiliades, A., Stulp, F., Calinon, S. and Mouret, J.-B. (2020). <strong>A Survey on Policy Search Algorithms for Learning Robot Controllers in a Handful of Trials</strong>. IEEE Trans. on Robotics, 32:2, 328-347.</a> <a href='paper7002.htm'><i class='fa fa-link fa-fw'></i>info</a> <a href='papers/Chatzilygeroudis-TRO2020.pdf' target='_blank'><i class='fa fa-file-pdf-o fa-fw'></i>pdf</a></p>
</div>
</div>
</div>






<br><br><br><br><br><br>
<a class='anchor' id='geometric'></a>
<h4 class='p-2 text-white bg-dark'>GEOMETRIC STRUCTURES</h4>
<br>
<div class='row'>
<div class='col-md-12'>
<p class='text-justify'>Because robots act in a physical world, <b>many fundamental problems in robotics involve geometry</b>, leading to an increased research effort in geometric methods for robotics in the recent years. To speed up skills acquisition, the prior knowledge about the physical world can be embedded within the representations of skills and associated learning algorithms. Our work focuses on <b>Riemannian geometry</b> and <b>geometric algebra</b> to provide such structures.</p>
<!--Data are not only vectors!-->
<figure class='figure p-3'><img class='figure-img img-fluid' src='images/Riemannian-small03.png'>
<figcaption class='figure-caption'>Data in robotics are characterized by simple but varied geometries. These structures are often underexploited in learning, planning, control and perception. In our work, we exploit <b>Riemannian geometry</b> to extend algorithms initially developed for standard Euclidean data, by taking into account the structures of these manifolds. In robotics, these manifolds include orientations, ellipsoids, graphs and subspaces.</figcaption>
</figure>

<figure class='figure p-3'><img class='figure-img img-fluid' src='images/GA-small01.jpg'>
<figcaption class='figure-caption'><b>Geometric algebra</b> can also be used to encode geometric primitives in a uniform manner, such as points, lines, planes, spheres, ellipsoids or quadric surfaces  (depicted in red), as well as the associated transformations $M$ to move from an initial state $X$ to a desired state $X_d$, which are called motors (depicted in green). In practice, it means that $M=f(X,X_d)$ can be described uniquely for different geometric objects, which is useful in various skillful manipulation contexts such as bimanual coordination, whole-body motion and human-robot collaboration.</figcaption>
</figure>

<!--<br><button class='btn btn-secondary btn-sm' data-toggle='collapse' data-target='#manipulability'>Learning, tracking and transfer of manipulability ellipsoids <b>[open]</b></button><br><br>
<div id='manipulability' class='collapse'>-->
<br><button class='btn btn-secondary btn-sm'>Learning, tracking and transfer of manipulability ellipsoids</button><br><br>
<div id='manipulability'>
<p class='text-justify'>Skills transfer can exploit <b>stiffness and manipulability ellipsoids</b>, in the form of <b>geometric descriptors</b> representing the skills to be transferred to the robot. As these ellipsoids lie on <b>symmetric positive definite (SPD) manifolds</b>, Riemannian geometry can be used to learn and reproduce these descriptors in a probabilistic manner.</p>
<figure class='figure p-3'><center><img class='figure-img img-fluid' style='width:70%;' src='images/manipulability-small02.png'></center></figure>
<div class='p-3 bg-light text-dark border'>
<p><b>Reference:</b></p>
<p><a href='paper3079.htm' class='nodecor'>Jaquier, N., Rozo, L. and Calinon, S. (2020). <strong>Analysis and Transfer of Human Movement Manipulability in Industry-like Activities</strong>. In Proc. of IEEE/RSJ Intl Conf. on Intelligent Robots and Systems (IROS), pp. 11131-11138.</a> <a href='paper3079.htm'><i class='fa fa-link fa-fw'></i>info</a> <a href='papers/Jaquier-IROS2020.pdf' target='_blank'><i class='fa fa-file-pdf-o fa-fw'></i>pdf</a></p>
</div><br>
</div>

<!--<button class='btn btn-secondary btn-sm' data-toggle='collapse' data-target='#GA'>Geometric algebra <b>[open]</b></button><br><br>
<div id='GA' class='collapse'>--> 
<button class='btn btn-secondary btn-sm'>Geometric algebra</button><br><br>
<div id='GA'>
<p class='text-justify'>Another promising candidate for handling geometric structures in robotics is the framework of <b>geometric algebra</b>, whose roots can be found in Clifford algebra, which can be seen as a fusion of quaternion and Grassmann algebras. Geometric algebra provides a unification of various frameworks popular in robotics, such as screw theory, Lie algebra or dual quaternions, while offering great generalization and extension perspectives.</p>
<p class='text-justify'>As a crude illustration of geometric algebra, think first of the way we represent the position of datapoints in a Cartesian space as a 3D vector. If we set some of these vector entries to 0, we can represent points in specific 2D planes of the 3D space (e.g, by representing a planar path in x-y by ignoring the z axis). In geometric algebra, we will store data in a vector of higher dimension (e.g., 32D), which will allow us to describe a richer variety of geometric objects, including constraints specified as spheres, circles, lines or segments. In analogy to the 3D vector, the non-zero values in this 32D vector will determine which geometric object it represents. Interestingly, both translation and rotation will be expressed in the same manner. Moreover, both states and actions will use the same formulation. These two properties provide a generic and homogeneous formulation for various robotics problems (kinematic and dynamic control, optimization, learning and planning).</p> 
<p class='text-justify'>Another informal parallel to illustrate the use of a 32-dimensional space is to consider the use of a unit quaternion to describe an orientation, whose components can be stored as a 4D vector. With this representation, for the very common task of moving both the position and orientation of a robot end effector, we need linear algebra for the translation part and quaternion algebra for the rotation part, which also most often involves a series a conversion from one to the other (e.g., to go through the different links of a kinematic chain). The use of dual quaternion is a step forward to avoid this situation, by embedding position information as another quaternion, resulting in a 8D vector that can be homogeneously treated with quaternion algebra. Geometric algebra follows a similar idea, but provides a more generic formulation, by using more dimensions to represent a richer set of objects. There are several variants described by a different number of dimensions, which offers to treat different categories of geometric problems, while keeping the same base formulation.</p>
<p class='text-justify'>In contrast to quaternion algebra whose theory relies on a generalization of complex numbers (the imaginary i, j, k components of the quaternion), the theory behind geometric algebra relies on a simpler principle using basis vectors as a starting point to describe different directions, which are combined with the notion of inner and outer products. In standard linear algebra, the inner/dot product of two vectors gives a scalar, while the outer product of two vectors typically takes the form of a cross product for 3D vectors, whose results in another 3D vector whose length is proportional to the surface swiped by the two vectors (in the plane formed by these two vectors). In geometric algebra, the notion of outer product is generalized to any dimension. First, the result is not expressed as a vector, and an oriented surface is instead defined so that the ordering of the two vectors matters. Then, multiple consecutive outer products can be defined, representing an oriented volume for the outer product of 3 vectors. This composition of the original basis vectors allows the formation of a higher dimension space in which many different geometric objects can be defined in a uniform manner. <b>Both geometric objects and transformations use the same algebra</b> and can then also be represented in a homogeneous manner as elements of this higher dimension space. Practically, geometric algebra allows geometric operations to be computed in a very fast way, with compact codes, see above figure.</p> 
<p class='text-justify'>This representation is thus an interesting candidate to provide <b>a single algebra for geometric reasoning</b>, alleviating the need of utilizing multiple algebras to express geometric relations. Our work leverages the capabilities of geometric algebra in robot manipulation tasks. We show in [Löw and Calinon, 2023] that the modeling of cost functions for optimal control can be done uniformly across different geometric primitives, leading to a low symbolic complexity of the resulting expressions and a geometric intuitiveness. Our benchmarks also show that such an approach provides faster resolution of robot kinematics problems than state-of-the-art software libraries used in robotics. In [Löw, Abbet and Calinon, 2024], we present a software library to allow other researchers and practitioners to leverage the power of geometric algebra in their own research.</p>
<!--<div class='p-3 bg-light text-dark border'>
<p><b>Reference:</b></p>
<p><a href='paper7009.htm' class='nodecor'>Löw, T. and Calinon, S. (2022). <strong>Geometric Algebra for Optimal Control with Applications in Manipulation Tasks</strong>. arXiv:2212.07237.</a> <a href='paper7009.htm'><i class='fa fa-link fa-fw'></i>info</a> <a href='papers/Loew-arXiv2022.pdf' target='_blank'><i class='fa fa-file-pdf-o fa-fw'></i>pdf</a></p>
</div><br>-->
</div>


<div class='p-3 bg-light text-dark border'>
<p><b>References:</b></p>
<p><a href='paper4039.htm' class='nodecor'>Calinon, S. (2020). <strong>Gaussians on Riemannian Manifolds: Applications for Robot Learning and Adaptive Control</strong>. IEEE Robotics and Automation Magazine (RAM), 27:2, 33-45.</a> <a href='paper4039.htm'><i class='fa fa-link fa-fw'></i>info</a> <a href='papers/Calinon-RAM2020.pdf' target='_blank'><i class='fa fa-file-pdf-o fa-fw'></i>pdf</a></p>
<p><a href='paper4040.htm' class='nodecor'>Jaquier, N., Rozo, L., Caldwell, D.G. and Calinon, S. (2021). <strong>Geometry-aware Manipulability Learning, Tracking and Transfer</strong>. International Journal of Robotics Research (IJRR), 40:2-3, 624-650.</a> <a href='paper4040.htm'><i class='fa fa-link fa-fw'></i>info</a> <a href='papers/Jaquier-IJRR2021.pdf' target='_blank'><i class='fa fa-file-pdf-o fa-fw'></i>pdf</a></p>
<p><a href='paper7009.htm' class='nodecor'>Löw, T. and Calinon, S. (2023). <strong>Geometric Algebra for Optimal Control with Applications in Manipulation Tasks</strong>. IEEE Trans. on Robotics (T-RO), 39:5, 3586-3600.</a> <a href='paper4057.htm'><i class='fa fa-link fa-fw'></i>info</a> <a href='papers/Loew-TRO2023.pdf' target='_blank'><i class='fa fa-file-pdf-o fa-fw'></i>pdf</a></p> 
<p><a href='paper4065.htm' class='nodecor'>Löw, T., Abbet, P. and Calinon, S. (2024). <strong>gafro: Geometric Algebra for Robotics</strong>. IEEE Robotics and Automation Magazine (RAM).</a> <a href='paper4065.htm'><i class='fa fa-link fa-fw'></i>info</a> <a href='papers/Loew-RAM2024.pdf' target='_blank'><i class='fa fa-file-pdf-o fa-fw'></i>pdf</a></p>
</div>
</div>
</div>





<br><br><br><br><br><br>
<a class='anchor' id='data'></a>
<h4 class='p-2 text-white bg-dark'>DATA STRUCTURES</h4>
<br>
<div class='row'>
<div class='col-md-12'>
<p class='text-justify'>Another type of structure that we exploit relates to the organization of data as <b>multidimensional arrays</b> (also called tensors). These data appear in various robotic tasks, either as the natural organization of sensory/motor data (tactile arrays, images, kinematic chains), as the result of standardized preprocessing steps (moving time windows, covariance features), data in multiple coordinate systems, or in the form of basis functions decompositions. Developed in the fields of <b>multilinear algebra</b> and <b>tensor methods</b>, these approaches extend linear factorization techniques such as singular value decomposition to <b>multilinear decomposition</b>, without requiring the transformation of the tensors to vectors or matrices. We exploit these techniques to provide robots with the capability <b>to learn tasks from only few tensor datapoints</b>, by relying on the multidimensional nature of the data.</p> 
<figure class='figure p-3'><img class='figure-img img-fluid' src='images/tensor-small02.png'></figure>

<!--<br><button class='btn btn-secondary btn-sm' data-toggle='collapse' data-target='#TTGO'>Global optimization with tensor train decomposition <b>[open]</b></button><br><br>
<div id='TTGO' class='collapse'>-->
<br><button class='btn btn-secondary btn-sm'>Global optimization with tensor train decomposition</button><br><br>
<div id='TTGO'>
<figure class='figure p-3'><center><img class='figure-img img-fluid' style='width:70%;' src='images/TT-pipeline-small01.jpg'></center>
<figcaption class='figure-caption'>Combination of global and local optimization for fast adaptation to new situations, by leveraging offline and online computation. 
<b>(a)</b> Local optimization algorithms such as iterative linear quadratic regulators (iLQR) requires good initial estimates to speed up convergence, to reach good local minima and to find diverse solutions. The figure shows an illustration with two decision variables and four local minima of a cost function.
<b>(b)</b> The decision variables space can be discretized to search for initial guesses near the local minima of the cost functions, which can be used to warm-start local optimizers.
<b>(c)</b> The naïve solution consists of evaluating the cost for each set of decision variables, which typically does not scale well when more than 2 or 3 decision variables are used, which is the case in robot control problems. For 2D decision variables, a cross approximation algorithm can be used to approximate the cost function (treated as a probability distribution). The algorithm iteratively searches for row and column indices to reconstruct the full distribution from a sparse subset of rows and columns (depicted in colors). It also simultaneously estimates the number of rows and columns required, corresponding to the rank of the matrix.
<b>(d)</b> Control problems in robotics have more than two dimensions, including both task parameters and decision variables. Learning the joint distribution of task parameters and decision variables can be conducted in an offline phase (through robot experiences and plays, possibly guided by human demonstrations). This offline learning phase is then followed by an online reproduction phase in which the robot needs to compute a controller as fast as possible, given a new set of task parameters describing a newly encountered situation.
<b>(e)</b> The cross approximation algorithm can be extended to tensor data by exploiting tensor train decomposition.
<b>(f)</b> This low-rank representation can be used for fast conditional sampling, allowing the robot to generate diverse controllers given a set of task parameters describing the situation/environment.
</figcaption>
</figure>
<br>
<p class='text-justify'>Learning and optimization problems in robotics are characterized by two types of variables: 1) <b>task parameters</b> representing the situation that the robot encounters, typically related to environment variables such as locations of objects, users or obstacles; and 2) <b>decision variables</b> related to actions that the robot takes, typically related to a controller acting within a given time window, or the use of basis functions to describe trajectories in control or state spaces. For each change of task parameters, decision variables need to be recomputed as fast as possible, so that the robot can fluently collaborate with users and can swiftly react to changes in its environment.</p>
<p class='text-justify'>Within the <a href='https://www.memmo-project.eu/' target='_blank'>MEMMO</a> and <a href='https://learn-real.eu/' target='_blank'>LEARN-REAL</a> projects, we investigate the roles of offline and online learning for optimal control. The problem is formalized as an optimization problem with a cost function to minimize, parameterized by task parameters and decision variables. The formulation transforms the minimization of a cost function into the maximization of a corresponding probability density function. Hence, the problem of finding the minima of a cost function is transformed into the problem of sampling the maxima of the density function. The proposed approach does not require gradients to be computed and can find multiple optima, which can be used for global optimization problems.</p>
<p class='text-justify'>The density function is modeled in the offline phase using a tensor train (TT) that exploits the structure between the task parameters and the decision variables. Tensor train factorization is a modern tool for the representation of complex nonlinear functions in variable separation form, with robust techniques such as TT-Cross to find the representation. It allows conditional sampling over the task parameters with priority for higher-density regions. This property is used for fast online decision-making, with local Gauss-Newton optimization to refine the results, see the above Figure for an overview.</p>
<p class='text-justify'>The proposed <b>tensor train for global optimization (TTGO)</b> approach has several advantages for robot skills acquisition. First, the problem formulation makes it a ubiquitous tool. It allows the distribution of computation into offline and online phases. It can cope with a mix of continuous and discrete variables for optimization thus providing an alternative to mixed-integer programming. By construction, the decision variables also stay within a bounded domain, which can be advantageous in some problems (e.g., joint angle limits, control bounds). Another important advantage of TTGO is that the underlying TT-cross method used to approximate the distribution in TT format can easily be extended to <b>various forms of human-guided learning</b>, by letting the user sporadically specify task parameters or decision variables within the iterative process. The first case can be used to provide a scaffolding mechanism for robot skill acquisition. The second case can be used for the robot to ask for help in specific situations.</p>
<p class='text-justify'>In the reference below, we demonstrated the capability of the approach for trajectory optimization within a varied set of control and planning problems with robot manipulators.</p>
<br>
</div>







<!--<button class='btn btn-secondary btn-sm' data-toggle='collapse' data-target='#ergodic'>Ergodic control applied to insertion tasks <b>[open]</b></button><br><br>
<div id='ergodic' class='collapse'>-->
<button class='btn btn-secondary btn-sm'>Ergodic control applied to insertion tasks</button><br><br>  
<div id='ergodic'>
<figure class='figure p-3'><center><img class='figure-img img-fluid' style='width:70%;' src='images/ergodic-small02.png'></center></figure>
<p class='text-justify'>In robotics, <b>ergodic control</b> extends the tracking principle by specifying a probability distribution over an area to cover instead of a trajectory to track. The original problem is formulated as a spectral multiscale coverage problem, typically requiring the <b>spatial distribution to be decomposed as Fourier series</b>. This approach does not scale well to control problems requiring exploration in search space of more than 2 dimensions. To address this issue, we propose the use of <b>tensor trains</b>, a recent <b>low-rank tensor decomposition</b> technique from the field of multilinear algebra. The proposed solution is efficient, both computationally and storage-wise, hence making it suitable for its online implementation in robotic systems. The approach is applied to a peg-in-hole insertion task requiring full 6D end-effector poses (see second reference below).</p>
</div>

<div class='p-3 bg-light text-dark border'>
<p><b>References:</b></p>
<p><a href='paper7008.htm' class='nodecor'>Shetty, S., Lembono, T., Löw, T. and Calinon, S. (2024). <strong>Tensor Train for Global Optimization Problems in Robotics</strong>. International Journal of Robotics Research (IJRR), 43:6, 811-839.</a> <a href='paper4059.htm'><i class='fa fa-link fa-fw'></i>info</a> <a href='papers/Shetty-IJRR2023.pdf' target='_blank'><i class='fa fa-file-pdf-o fa-fw'></i>pdf</a></p>
<a href='paper3096.htm' class='nodecor'>Shetty, S., Xue, T. and Calinon, S. (2024). <strong>Generalized Policy Iteration using Tensor Approximation for Hybrid Control</strong>. In Proc. Intl Conf. on Learning Representations (ICLR).</a> <a href='paper3096.htm'><i class='fa fa-link fa-fw'></i>info</a> <a href='papers/Shetty-ICLR2024.pdf' target='_blank'><i class='fa fa-file-pdf-o fa-fw'></i>pdf</a></p>
<p><a href='paper4048.htm' class='nodecor'>Shetty, S., Silvério, J. and Calinon, S. (2022). <strong>Ergodic Exploration using Tensor Train: Applications in Insertion Tasks</strong>. IEEE Trans. on Robotics (T-RO), 38:2, 906-921.</a> <a href='paper4048.htm'><i class='fa fa-link fa-fw'></i>info</a> <a href='papers/Shetty-TRO2021.pdf' target='_blank'><i class='fa fa-file-pdf-o fa-fw'></i>pdf</a></p>
</div>
</div>
</div>




<br><br><br><br><br><br>
<a class='anchor' id='combination'></a>
<h4 class='p-2 text-white bg-dark'>COMBINATION STRUCTURES</h4>
<br>
<div class='row'>
<div class='col-md-12'>
<p class='text-justify'>Movement primitives are often used in robot learning as high-level "bricks" of motion from a dictionary that can be re-organized in series and in parallel. Our work extends this notion to <b>behavior primitives</b>, which form a richer set of behaviors (see (a) in the figure below). These behavior primitives correspond to controllers that are either myopic or anticipative, with either time-independent or time-dependent formulations.</p>
<!-- We advocate the importance of superposing controllers with full weight matrices instead of scalar weights.-->
<p class='text-justify'>We propose to formalize the combination of behavior primitives as an information fusion problem in which several sources of information can be modeled as probability distributions. The <b>product of experts (PoE)</b> is a machine learning technique modeling a probability distribution by combining the output from several simpler distributions. The core idea is to combine several distributions (called experts) by multiplying their density functions. This allows each expert to make decisions on the basis of a few dimensions, without having to cover the full dimensionality of a problem. A PoE corresponds to an "and" operation, which contrasts with a mixture model that corresponds to an "or" operation (by combining several probability distributions as a weighted sum of their density functions). Thus, each component in a PoE represents a soft constraint. For an event to be likely under a product model, all constraints must be (approximately) satisfied. In contrast, in a mixture model, an event is likely if it matches (approximately) with any single expert.</p>
<figure class='figure p-3'><img class='figure-img img-fluid' src='images/PoE_small01.jpg'></figure>
<p class='text-justify'>With Gaussian distributions, the fusion problem simplifies to a <b>product of Gaussians (PoG)</b>, which can be solved analytically, where the distributions can either represent robot commands at the current time step (myopic control system), or trajectory distributions in the control space (anticipative planning system).</p>
<p class='text-justify'>State estimation is also classically solved as an information fusion problem, resulting in a product of Gaussians that takes into account uncertainty in motion and sensor(s) models (a well-known example is the Kalman filter), see (b) in the figure above. We propose to treat the combination of behavior primitives within a similar mathematical framework, by relying on products of experts, where each expert takes care of a specific aspect of the task to achieve.</p>
<p class='text-justify'>This approach allows the <b>orchestration of different controllers</b>, which can be learned separately or altogether (by variational inference). With this formulation, the robot can counteract perturbations that have an impact on the fulfillment of the task, while ignoring other perturbations. It also allows us to create bridges with research in biomechanics and motor control, with formulations including minimal intervention principles, uncontrolled manifolds or optimal feedback control.</p>
<!--This approach allows us to combine control, planning and perception features in an efficient manner, by allowing multiple behavior primitives to be orchestrated in parallel (including prioritization with null-space projection structures). In this framework, each behavior primitive contributes to the task by taking into account the (co)variations allowed in a task and the uncertainty of the expertise.-->

<!--<button class='btn btn-secondary btn-sm' data-toggle='collapse' data-target='#taskparameterized'>Task-parameterized movements <b>[open]</b></button><br><br>
<div id='taskparameterized' class='collapse'>-->
<button class='btn btn-secondary btn-sm'>Task-parameterized movements</button><br><br> 
<div id='taskparameterized'>
<figure class='figure p-3'><img class='figure-img img-fluid' src='images/TPmodels01.jpg'></figure>
<p class='text-justify'>To facilitate the acquisition of manipulation skills, <b>task-parameterized models</b> can be exploited to take into account that <b>motions typically relates to objects, tools or landmarks</b> in the robot's workspace. The approach consists of <b>encoding a movement in multiple coordinate systems</b> (e.g., from the perspectives of different objects), in the form of trajectory distributions. In a new situation (e.g., for new object locations), the reproduction problem corresponds to a fusion problem, where the variations in the different coordinate systems are exploited to generate a movement reference tracked with variable gains, providing the robot with a <b>variable impedance behavior</b> that automatically adapts to the precision required in the different phases of the task. For example, in a pick-and-place task, the robot will be stiff if the object needs to be reached/dropped in a precise way, and will remain compliant in the other parts of the task.</p> 
<p class='text-justify'>Our ongoing work explores the extension of the task-parameterized principle to a richer set of behaviors, including <b>coordinate systems that take into account symmetries</b> (e.g., cylindrical and spherical coordinate systems) and <b>nullspace projection structures</b>.</p>
<div class='p-3 bg-light text-dark border'>
<p><b>References:</b></p>
<p><a href='paper4018.htm' class='nodecor'>Calinon, S. (2016). <strong>A Tutorial on Task-Parameterized Movement Learning and Retrieval</strong>. Intelligent Service Robotics (Springer), 9:1, 1-29.</a> <a href='paper4018.htm'><i class='fa fa-link fa-fw'></i>info</a> <a href='papers/Calinon-JIST2015.pdf' target='_blank'><i class='fa fa-file-pdf-o fa-fw'></i>pdf</a></p>
<p><a href='paper4033.htm' class='nodecor'>Silvério, J., Calinon, S., Rozo, L. and Caldwell, D.G. (2019). <strong>Learning Task Priorities from Demonstrations</strong>. IEEE Transactions on Robotics, 35:1, 78-94.</a> <a href='paper4033.htm'><i class='fa fa-link fa-fw'></i>info</a> <a href='papers/Silverio-TRO2019.pdf' target='_blank'><i class='fa fa-file-pdf-o fa-fw'></i>pdf</a></p>
</div><br>
</div>

<!--<button class='btn btn-secondary btn-sm' data-toggle='collapse' data-target='#optimalcontrol'>Probabilistic optimal control <b>[open]</b></button><br><br>
<div id='optimalcontrol' class='collapse'> -->
<button class='btn btn-secondary btn-sm'>Probabilistic optimal control</button><br><br> 
<div id='optimalcontrol'>
<figure class='figure p-3'><center><img class='figure-img img-fluid' style='width:70%;' src='images/LQT-small02.png'></center></figure>
<p class='text-justify'><b>Linear quadratic tracking (LQT)</b> is a simple form of optimal control that trades off tracking and control costs expressed as quadratic terms over a time horizon, with the evolution of the state described in a linear form. This constrained problem can be solved by expressing the state and the control commands as trajectories, corresponding to a least squares solution. A <b>probabilistic interpretation of the LQT solution</b> can be built by using the residuals of this estimate.</p>
<p class='text-justify'>This approach allows the <b>creation of bridges between learning and control</b>. For example, in learning from demonstration, the observed (co)variations in a task can be formulated as an LQT objective function, which then provides a trajectory distribution in control space that can be converted to a trajectory distribution in state space. All the operations are analytic and only exploit basic linear algebra.</p>
<p class='text-justify'>The proposed approach can also be extended to <b>model predictive control (MPC), iterative LQR (iLQR) and differential dynamic programming (DDP)</b>, whose solution needs this time to be interpreted locally at each iteration step of the algorithm.</p>
<div class='p-3 bg-light text-dark border'>
<p><b>References:</b></p>
<p><a href='paper5004.htm' class='nodecor'>Calinon, S. and Lee, D.  (2019). <strong>Learning Control</strong>. Vadakkepat, P. and Goswami, A. (eds.). Humanoid Robotics: a Reference, pp. 1261-1312. Springer.</a> <a href='paper5004.htm'><i class='fa fa-link fa-fw'></i>info</a> <a href='papers/Calinon-Lee-learningControl.pdf' target='_blank'><i class='fa fa-file-pdf-o fa-fw'></i>pdf</a></p>
<p><a href='paper3054.htm' class='nodecor'>Calinon, S. (2016). <strong>Stochastic learning and control in multiple coordinate systems</strong>. Intl Workshop on Human-Friendly Robotics (HFR).</a> <a href='paper3054.htm'><i class='fa fa-link fa-fw'></i>info</a> <a href='papers/Calinon-HFR2016.pdf' target='_blank'><i class='fa fa-file-pdf-o fa-fw'></i>pdf</a></p>
</div><br>
</div>

<!-- + Berio -->

<div class='p-3 bg-light text-dark border'>
<p><b>Reference:</b></p>
<p><a href='paper4050.htm' class='nodecor'>Pignat, E., Silvério, J. and Calinon, S. (2022). <strong>Learning from Demonstration using Products of Experts: Applications to Manipulation and Task Prioritization</strong>. International Journal of Robotics Research, 41:2, 163-188.</a> <a href='paper4050.htm'><i class='fa fa-link fa-fw'></i>info</a> <a href='papers/Pignat-IJRR2021.pdf' target='_blank'><i class='fa fa-file-pdf-o fa-fw'></i>pdf</a></p>
</div>
</div>
</div>




<br><br><br><br><br><br>
<a class='anchor' id='learning'></a>
<h4 class='p-2 text-white bg-dark'>LEARNING STRUCTURES</h4>
<br>
<div class='row'>
<div class='col-md-12'>
<img src='images/ML_robotics-small03.jpg' class='wrappedimg'>
<p class='text-justify'>To reduce the amount of required data, another opportunity to seize is that <b>machine learning in robotics goes beyond the standard training-set and testing-set paradigm</b>.</p>
<p class='text-justify'>Indeed, we can exploit a number of <b>interactive learning mechanisms</b> to acquire/generate better data on-the-spot, including active learning, machine teaching (by generating data to train our robots), curriculum learning (by providing data of increased complexity that adapt to the learner), and bilateral interactions that rely on several <b>social mechanisms to transfer skills more efficiently</b>. Thus, skills acquisition in robotics is <b>a scaffolding process rather than a standard learning process</b>. In this scaffolding metaphor, the robot first needs a lot of structures, and the structures can be progressively dismantled when the robot progresses. There is thus a continuous evolution from full assistance to full autonomy.</p>
<img src='images/learningStrategies-small01.jpg' class='wrappedimg'>
<p class='text-justify'>We can also greatly benefit from the <b>orchestration of several learning modalities</b> that can jointly be used to transfer skills, and evaluate the current capability of the robot to execute the task. This can improve the robustness of skill acquisition by allowing diverse forms of environment and user constraints to be considered, and an improved assessment of the robot knowledge (by testing the acquired knowledge in diverse situations).<p> 
<p class='text-justify'>The other important advantage is that <b>this orchestration allows each individual learning modality to be simplified</b>, as skills acquisition with a single learning strategy can be unnecessarily complex. Indeed, we could not learn to play a sport efficiently without practice, by only observing others play. We could also not acquire efficiently a fabrication skill with only the desired end-goal. We instead need to observe an expert or to to be guided throughout the process to acquire the underlying fabrication strategies. Similarly to us, <b>robots cannot acquire skills efficiently by using a single learning modality</b>.</p>
<p class='text-justify'>Thus, instead of focusing on the improvement of algorithms and models for a specific learning strategy, I believe that robotics could highly benefit from the <b>meta-learning problem of combining learning modalities</b>, without defining the sequence and organization in advance.</p>
<div class='p-3 bg-light text-dark border'>
<p><b>Reference:</b></p>
<p><a href='paper4046.htm' class='nodecor'>Kulak, T. and Calinon, S. (2023). <strong>Combining Social and Intrinsically-Motivated Learning for Multi-Task Robot Skill Acquisition</strong>. IEEE Trans. on Cognitive and Developmental Systems, 15:2, 385-394.</a> <a href='paper4046.htm'><i class='fa fa-link fa-fw'></i>info</a> <a href='papers/Kulak-TCDS2023.pdf' target='_blank'><i class='fa fa-file-pdf-o fa-fw'></i>pdf</a></p>
</div>
</div>
</div>


</div><!-- /.main-template -->
</div><!-- /.container -->


<!-- Bootstrap core JavaScript placed at the end of the document so the pages load faster -->
<script src="https://code.jquery.com/jquery-3.1.1.slim.min.js" integrity="sha384-A7FZj7v+d/sdmMqp/nOQwliLvUsJfDHW+k9Omg/a/EheAdgtzNs3hpfag6Ed950n" crossorigin="anonymous"></script>
<script>window.jQuery || document.write('<script src="../../assets/js/vendor/jquery.min.js"><\/script>')</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/tether/1.4.0/js/tether.min.js" integrity="sha384-DztdAPBWPRXSA/3eYEEUWrWCy7G5KFbe8fFjk5JAIxUYHKkDx6Qin1DkWx51bBrb" crossorigin="anonymous"></script>
<script src="js/bootstrap.min.js"></script>
<!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
<!--<script src="assets/js/ie10-viewport-bug-workaround.js"></script>-->
</body>
</html>
