<!DOCTYPE html>
<html lang='en'>
<head>
<meta charset='utf-8'>
<meta name='viewport' content='width=device-width, initial-scale=1, shrink-to-fit=no'>
<meta name='description' content='Sylvain Calinon'>
<meta name='author' content='Sylvain Calinon'>
<meta name='keywords' content='Sylvain Calinon, robotics, machine learning, robot learning, human-robot interaction, human-robot collaboration, learning from demonstration, programming by demonstration, artificial intelligence'>
<meta name='theme-color' content='#343a40'>
<link rel='icon' href='images/favicon.ico'>
<title>Sylvain Calinon</title>
<link href='css/bootstrap.min.css' rel='stylesheet'>
<link href='css/main-template.css' rel='stylesheet'>
<link href='font-awesome/css/font-awesome.min.css' rel='stylesheet'>
<link href='https://fonts.googleapis.com/css?family=Lobster|Raleway' rel='stylesheet'> 
<script type='text/x-mathjax-config'>
MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
});
</script>
<script type='text/javascript' async src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML' async></script>
</head>
<body>
<nav class='navbar navbar-expand-lg navbar-dark bg-dark fixed-top'>
<button class='navbar-toggler navbar-toggler-right' type='button' data-toggle='collapse' data-target='#navbarsExampleDefault' aria-controls='navbarsExampleDefault' aria-expanded='false' aria-label='Toggle navigation'>
<span class='navbar-toggler-icon'></span>
</button>
<a class='navbar-brand' href='index.htm'>
<h3 style='display: inline-block;'>Sylvain Calinon</h3>
<img src='images/pbd-thumbnail02.png' style='display: inline-block; margin-left: 10px;'>
</a>

<div class='collapse navbar-collapse' id='navbarsExampleDefault'>
<ul class='navbar-nav mr-auto'>
<li class='nav-item'><a class='nav-link' href='index.htm'>News</a></li>
<li class='nav-item'><a class='nav-link' href='cv.htm'>CV</a></li>
<li class='nav-item active'><a class='nav-link' href='research.htm'>Research <span class='sr-only'>(current)</span></a></li>
<li class='nav-item'><a class='nav-link' href='publications.htm'>Publications</a></li>
<li class='nav-item'><a class='nav-link' href='teaching.htm'>Teaching</a></li>
<li class='nav-item'><a class='nav-link' href='book.htm'>Book</a></li>
<li class='nav-item'><a class='nav-link' href='videos.htm'>Videos</a></li>
<li class='nav-item'><a class='nav-link' href='codes.htm'>Codes</a></li>
<li class='nav-item'><a class='nav-link' href='open-positions.htm'>Open positions </a></li>
<li class='nav-item'><a class='nav-link' href='contact.htm'>Contact/Links</a></li>	
</ul>
</div>
</nav>

<div class='container'>
<div class='main-template'>

<h3>Robot Learning & Interaction</h3>

<p class='text-justify'>My work focuses on <b>human-centered robotics applications</b> in which the robots can <b>acquire new skills from only few demonstrations and interactions</b>. It requires the development of models that can <b>exploit the structure and geometry of the acquired data</b> in an efficient way, the development of optimal control techniques that can <b>exploit the learned task variations and coordination patterns</b>, and the development of intuitive interfaces to acquire meaningful demonstrations.</p>

<p class='text-justify'>The developed approaches can be applied to a wide range of manipulation skills, with robots that are either close to us (<b>assistive and industrial robots</b>), parts of us (<b>prosthetics</b>), or far away from us (<b>teleoperation</b>). My research is supported by the <a href='https://ec.europa.eu/programmes/horizon2020/' target='_blank'>European Commission</a>, by the <a href='http://www.snf.ch/en/' target='_blank'>Swiss National Science Foundation</a>, and by the <a href='https://www.innosuisse.ch/inno/en/home.html' target='_blank'>Swiss Innovation Agency</a>.</p> 



<br>
<a class='anchor' id='smalldata'></a>
<h4 class='p-2 text-white bg-dark'>LEARNING IN A HANDFUL OF TRIALS</h4>
<div class='row'>
<div class='col-md-12'>
<img src='images/datafeed-small03.png' class='wrappedimg'>
<p class='text-justify'>The field of machine learning has evolved toward approaches relying on huge amounts of data. In several application domains, these big datasets are already available, or are inexpensive to collect/produce. In contrast, robotics is characterized by a different problem setting. It can be viewed a <b>wide-ranging data problem</b>, with models that can start learning from small datasets, and that can still exploit more data if such data become available during the robot's lifespan.</p> 
<p class='text-justify'>The current trend of machine learning relying on big datasets can be harmful to robotics. First, in contrast to other fields, the data formats in robotics vary significantly across tasks, environments, users and platforms (different sensors and actuators, not only in formats but also in modalities and organizations). Then, the learned models often need to be interpretable to provide guarantees and to be linked to other techniques. For these reasons, my work focuses on <b>robot learning approaches that can rely on only few demonstrations or trials</b>.</p>
<p class='text-justify'>The main challenge boils down to <b>finding structures that can be used in a wide range of tasks</b>, which include (from high level to low level):
<ul>
<li><a href='#learning'>Learning structures</a></li>
<li><a href='#combination'>Combination structures</a></li>
<li><a href='#geometric'>Geometric structures</a></li>
<li><a href='#data'>Data structures</a></li>
</ul>
<p class='text-justify'>Efficient robot skills acquistion requires the right trade-off between learning and exploitation of these different form of structures (at model and algorithm levels).</p>
<div class='p-3 bg-light text-dark border'>
<p><b>Reference:</b></p>
<p><a href='paper7002.htm' class='nodecor'>Chatzilygeroudis, K., Vassiliades, A., Stulp, F., Calinon, S. and Mouret, J.-B. (2020). <strong>A Survey on Policy Search Algorithms for Learning Robot Controllers in a Handful of Trials</strong>. IEEE Trans. on Robotics, 32:2, 328-347.</a> <a href='paper7002.htm'><i class='fa fa-link fa-fw'></i>info</a> <a href='papers/Chatzilygeroudis-TRO2020.pdf' target='_blank'><i class='fa fa-file-pdf-o fa-fw'></i>pdf</a></p>
</div>
</div>
</div>


<br>
<a class='anchor' id='learning'></a>
<h4 class='p-2 text-white bg-dark'>LEARNING STRUCTURES</h4>
<div class='row'>
<div class='col-md-12'>
<img src='images/ML_robotics-small03.jpg' class='wrappedimg'>
<p class='text-justify'>To reduce the amount of required data, a first opportunity to seize is that <b>machine learning in robotics goes beyond the standard training-set and testing-set paradigm</b>.</p>
<p class='text-justify'>Indeed, we can exploit a number of <b>interactive learning mechanisms</b> to acquire/generate better data on-the-spot, including active learning, machine teaching (by generating data to train our robots), curriculum learning (by providing data of increased complexity that adapt to the learner), and bilateral interactions that rely on several <b>social mechanisms to transfer skills more efficiently</b>. Thus, skills acquisition in robotics is <b>a scaffolding process rather than a standard learning process</b>. In this scaffolding metaphor, the robot first needs a lot of structures, and the structures can be progressively dismantled when the robot progresses. There is thus a continuous evolution from full assistance to full autonomy.</p>
<img src='images/learningStrategies-small01.jpg' class='wrappedimg'>
<p class='text-justify'>We can also greatly benefit from the <b>orchestration of several learning modalities</b> that can jointly be used to transfer skills, and evaluate the current capability of the robot to execute the task. This can improve the robustness of skill acquisition by allowing diverse forms of environment and user constraints to be considered, and an improved assesment of the robot knowledge (by testing the acquired knowledge in diverse situations).<p> 
<p class='text-justify'>The other important advantage is that <b>this orchestration allows each individual learning modality to be simplified</b>, as skills acquistion with a single learning strategy can be unnecessarily complex. Indeed, we could not learn to play a sport efficiently without practice, by only observing others play. We could also not acquire efficiently a fabrication skill with only the desired end-goal. We instead need to observe an expert or to to be guided throughout the process to acquire the underlying fabrication strategies. Similarly to us, <b>robots cannot acquire skills efficiently by using a single learning modality</b>.</p>
<p class='text-justify'>Thus, instead of focusing on the improvement of algorithms and models for a specific learning strategy, I believe that robotics could highly benefit from the <b>meta-learning problem of combining learning modalities</b>, without defining the sequence and organization in advance.</p>
<div class='p-3 bg-light text-dark border'>
<p><b>Reference:</b></p>
<p><a href='paper4046.htm' class='nodecor'>Kulak, T. and Calinon, S. (2021). <strong>Combining Social and Intrinsically-Motivated Learning for Multi-Task Robot Skill Acquisition</strong>. IEEE Trans. on Cognitive and Developmental Systems.</a> <a href='paper4046.htm'><i class='fa fa-link fa-fw'></i>info</a> <a href='papers/Kulak-TCDS2021.pdf' target='_blank'><i class='fa fa-file-pdf-o fa-fw'></i>pdf</a></p>
</div>
</div>
</div>



<br>
<a class='anchor' id='combination'></a>
<h4 class='p-2 text-white bg-dark'>COMBINATION STRUCTURES</h4>
<div class='row'>
<div class='col-md-12'>
<p class='text-justify'>Movement primitives are often used in robot learning as high-level "bricks" of motion from a dictionary that can be re-organized in series and in parallel. Our work extends this notion to <b>behavior primitives</b>, which form a richer set of behaviors (see (a) in the figure below). These behavior primitives correspond to controllers that are either myopic or anticipative, with either time-independent or time-dependent formulations.</p>
<!-- We advocate the importance of superposing controllers with full weight matrices instead of scalar weights.-->
<p class='text-justify'>We propose to formalize the combination of behavior primitives as an information fusion problem in which several sources of information can be modeled as probability distributions. The <b>product of experts (PoE)</b> is a machine learning technique modeling a probability distribution by combining the output from several simpler distributions. The core idea is to combine several distributions (called experts) by multiplying their density functions. This allows each expert to make decisions on the basis of a few dimensions, without having to cover the full dimensionality of a problem. A PoE corresponds to an "and" operation, which contrasts with a mixture model that corresponds to an "or" operation (by combining several probability distributions as a weighted sum of their density functions). Thus, each component in a PoE represents a soft constraint. For an event to be likely under a product model, all constraints must be (approximately) satisfied. In contrast, in a mixture model, an event is likely if it matches (approximately) with any single expert.</p>
<figure class='figure p-3'><img class='figure-img img-fluid' src='images/PoE-small01.png'></figure>
<p class='text-justify'>With Gaussian distributions, the fusion problem simplifies to a <b>product of Gaussians (PoG)</b>, which can be solved analytically, where the distributions can either represent robot commands at the current time step (myopic control system), or trajectory distributions in the control space (anticipative planning system).</p>
<p class='text-justify'>State estimation is also classically solved as an information fusion problem, resulting in a product of Gaussians that takes into account uncertainty in motion and sensor(s) models (a well-known example is the Kalman filter), see (b) in the figure above. We propose to treat the combination of behavior primitives within a similar mathematical framework, by relying on products of experts, where each expert takes care of a specific aspect of the task to achieve.</p>
<p class='text-justify'>This approach allows the <b>orchestration of different controllers</b>, which can be learned separately or altogether (by variational inference). With this formulation, the robot can counteract perturbations that have an impact on the fulfillment of the task, while ignoring other perturbations. It also allows us to create bridges with research in biomechanics and motor control, with formulations including minimal intervention principles, uncontrolled manifolds or optimal feedback control.</p>
<!--This approach allows us to combine control, planning and perception features in an efficient manner, by allowing multiple behavior primitives to be orchestrated in parallel (including prioritization with null-space projection structures). In this framework, each behavior primitive contributes to the task by taking into account the (co)variations allowed in a task and the uncertainty of the expertise.-->
<div class='p-3 bg-light text-dark border'>
<p><b>Reference:</b></p>
<p><a href='paper7005.htm' class='nodecor'>Pignat, E., Silvério, J. and Calinon, S. (2020). <strong>Learning from Demonstration using Products of Experts: Applications to Manipulation and Task Prioritization</strong>. arXiv:2010.03505.</a> <a href='paper7005.htm'><i class='fa fa-link fa-fw'></i>info</a> <a href='papers/Pignat-arXiv2020.pdf' target='_blank'><i class='fa fa-file-pdf-o fa-fw'></i>pdf</a></p>
</div>
</div>
</div>


<br>
<a class='anchor' id='geometric'></a>
<h4 class='p-2 text-white bg-dark'>GEOMETRIC STRUCTURES</h4>
<div class='row'>
<div class='col-md-12'>
<p class='text-justify'><b>Data are not only vectors!</b> This is especially true in robotics, where the encountered data are characterized by simple but varied geometries. These structures are often underexploited in learning, planning, control and perception. In our work, we exploit <b>Riemannian geometry</b> to extend algorithms initially developed for standard Euclidean data, by taking into account the structures of these manifolds. In robotics, these manifolds include orientations, ellipsoids, graphs and subspaces (see figure below).</p>
<figure class='figure p-3'><img class='figure-img img-fluid' src='images/Riemannian-small03.png'></figure>
<div class='p-3 bg-light text-dark border'>
<p><b>References:</b></p>
<p><a href='paper4039.htm' class='nodecor'>Calinon, S. (2020). <strong>Gaussians on Riemannian Manifolds: Applications for Robot Learning and Adaptive Control</strong>. IEEE Robotics and Automation Magazine (RAM), 27:2, 33-45.</a> <a href='paper4039.htm'><i class='fa fa-link fa-fw'></i>info</a> <a href='papers/Calinon-RAM2020.pdf' target='_blank'><i class='fa fa-file-pdf-o fa-fw'></i>pdf</a></p>
<p><a href='paper4040.htm' class='nodecor'>Jaquier, N., Rozo, L., Caldwell, D.G. and Calinon, S. (2021). <strong>Geometry-aware Manipulability Learning, Tracking and Transfer</strong>. International Journal of Robotics Research (IJRR), 40:2-3, 624-650.</a> <a href='paper4040.htm'><i class='fa fa-link fa-fw'></i>info</a> <a href='papers/Jaquier-IJRR2021.pdf' target='_blank'><i class='fa fa-file-pdf-o fa-fw'></i>pdf</a></p>
</div>
</div>
</div>



<br>
<a class='anchor' id='data'></a>
<h4 class='p-2 text-white bg-dark'>DATA STRUCTURES</h4>
<div class='row'>
<div class='col-md-12'>
<p class='text-justify'>Another type of structure that we exploit relates to the organization of data as <b>multidimensional arrays</b> (also called tensors). These data appear in various robotic tasks, either as the natural organization of sensory/motor data (tactile arrays, images, kinematic chains), or as the result of standardized preprocessing steps (moving time windows, covariance features). Developed in the fields of <b>multilinear algebra</b> and <b>tensor methods</b>, these approaches extend linear factorization techniques such as singular value decomposition to <b>multilinear decomposition</b>, without requiring the transformation of the tensors to vectors or matrices. We exploit these techniques to provide robots with the capability <b>to learn tasks from only few tensor datapoints</b>, by relying on the multidimensional nature of the data.</p> 
<figure class='figure p-3'><img class='figure-img img-fluid' src='images/tensor-small02.png'></figure>
<div class='p-3 bg-light text-dark border'>
<p><b>References:</b></p>
<p><a href='paper7006.htm' class='nodecor'>Shetty, S., Silvério, J. and Calinon, S. (2021). <strong>Ergodic Exploration using Tensor Train: Applications in Insertion Tasks</strong>. arXiv:2101.04428.</a> <a href='paper7006.htm'><i class='fa fa-link fa-fw'></i>info</a> <a href='papers/Shetty-arXiv2021.pdf' target='_blank'><i class='fa fa-file-pdf-o fa-fw'></i>pdf</a></p>
<p><a href='paper4047.htm' class='nodecor'>Jaquier, N., Haschke, R. and Calinon, S. (2021). <strong>Tensor-variate mixture of experts for proportional myographic control of a robotic hand</strong>. Robotics and Autonomous Systems.</a> <a href='paper4047.htm'><i class='fa fa-link fa-fw'></i>info</a> <a href='papers/Jaquier-RAS2021.pdf' target='_blank'><i class='fa fa-file-pdf-o fa-fw'></i>pdf</a></p>
</div>
</div>
</div>


</div><!-- /.main-template -->
</div><!-- /.container -->


<!-- Bootstrap core JavaScript placed at the end of the document so the pages load faster -->
<script src="https://code.jquery.com/jquery-3.1.1.slim.min.js" integrity="sha384-A7FZj7v+d/sdmMqp/nOQwliLvUsJfDHW+k9Omg/a/EheAdgtzNs3hpfag6Ed950n" crossorigin="anonymous"></script>
<script>window.jQuery || document.write('<script src="../../assets/js/vendor/jquery.min.js"><\/script>')</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/tether/1.4.0/js/tether.min.js" integrity="sha384-DztdAPBWPRXSA/3eYEEUWrWCy7G5KFbe8fFjk5JAIxUYHKkDx6Qin1DkWx51bBrb" crossorigin="anonymous"></script>
<script src="js/bootstrap.min.js"></script>
<!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
<!--<script src="assets/js/ie10-viewport-bug-workaround.js"></script>-->
</body>
</html>
